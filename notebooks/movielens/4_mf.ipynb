{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IPython\n",
    "from pathlib import Path\n",
    "import os\n",
    "locals = IPython.extract_module_locals() # type: ignore\n",
    "notebook_name = \"/\".join(locals[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "os.chdir(Path(notebook_name).parent.parent.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from recsys.evaluation.metrics import map_k, precision_k, recall_k\n",
    "from recsys.evaluation.evaluation import recommendation_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\".data/movielens/base\")\n",
    "\n",
    "movies = pd.read_csv(base_path / \"movies.csv\")\n",
    "links = pd.read_csv(base_path / \"links.csv\")\n",
    "tags = pd.read_csv(base_path / \"tags.csv\")\n",
    "\n",
    "intermediate_path = Path(\".data/movielens/intermediate/1\")\n",
    "\n",
    "ratings = pd.read_parquet(intermediate_path / \"ratings.parquet\")\n",
    "ratings_train = pd.read_parquet(intermediate_path / \"ratings_train.parquet\")\n",
    "ratings_validation = pd.read_parquet(intermediate_path / \"ratings_validation.parquet\")\n",
    "user_id_map = pd.read_parquet(intermediate_path / \"user_id_map.parquet\")\n",
    "movie_id_map = pd.read_parquet(intermediate_path / \"movie_id_map.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162414 47396 15630129\n"
     ]
    }
   ],
   "source": [
    "n_users = user_id_map[\"userId\"].nunique()\n",
    "n_items = movie_id_map['movieId'].nunique()\n",
    "\n",
    "print(n_users, n_items, ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from functools import cached_property\n",
    "from typing import Any\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    u_id = torch.cat([x[\"u_id\"] for x in batch])\n",
    "    i_id = torch.cat([x[\"i_id\"] for x in batch])\n",
    "    target = torch.cat([x[\"target\"] for x in batch])\n",
    "    return {\"u_id\": u_id, \"i_id\": i_id, \"target\": target}\n",
    "\n",
    "\n",
    "def eval_collate_fn(batch):\n",
    "    u_id = torch.cat([x[\"u_id\"] for x in batch])\n",
    "    return {\"u_id\": u_id}\n",
    "\n",
    "\n",
    "def approx_neg_sampl(n_items: int, neg_sampl: int) -> torch.Tensor:\n",
    "    return torch.randint(low=0, high=n_items, size=(neg_sampl,), dtype=torch.int32)\n",
    "\n",
    "\n",
    "def batch_dict_to_device(batch: dict[str, Any], device: torch.device) -> dict[str, Any]:\n",
    "    return {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "\n",
    "class DotProd(nn.Module):\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(x * y, dim=1)\n",
    "\n",
    "\n",
    "class MFDataset(Dataset):\n",
    "    def __init__(self, relations: pd.DataFrame, users: pd.DataFrame, items: pd.DataFrame, namings: dict[str, str], neg_sampl: int = 5):\n",
    "        self._df = torch.from_numpy(relations.values).to(torch.int32)\n",
    "        self._users = torch.from_numpy(users.unique()).to(torch.float32)\n",
    "        self._items = torch.from_numpy(items.unique()).to(torch.float32)\n",
    "        self._neg_sampl = neg_sampl\n",
    "\n",
    "    @property\n",
    "    def _n_users(self) -> int:\n",
    "        return len(self._users)\n",
    "\n",
    "    @property\n",
    "    def _n_items(self) -> int:\n",
    "        return len(self._items)\n",
    "\n",
    "    @cached_property\n",
    "    def users_set(self) -> torch.Tensor:\n",
    "        return torch.arange(self._n_users, dtype=torch.int32)\n",
    "\n",
    "    @cached_property\n",
    "    def items_set(self) -> torch.Tensor:\n",
    "        return torch.arange(self._n_items, dtype=torch.int32)\n",
    "\n",
    "    @cached_property\n",
    "    def ground_truth(self) -> torch.Tensor:\n",
    "        return self._df.T\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict[str, Any]:\n",
    "        row = self._df[idx]\n",
    "        user = row[0].unsqueeze(0)\n",
    "        items = row[1].unsqueeze(0)\n",
    "\n",
    "        u_id = user.repeat(self._neg_sampl + 1)\n",
    "        i_id = torch.cat([items, approx_neg_sampl(self._n_items, self._neg_sampl)])\n",
    "        target = torch.tensor([1.0] + [0.0] * self._neg_sampl, dtype=torch.float)\n",
    "\n",
    "        return {\"u_id\": u_id, \"i_id\": i_id, \"target\": target}\n",
    "\n",
    "\n",
    "class MFEvalDataset(IterableDataset):\n",
    "    def __init__(self, base_dataset: MFDataset, user_batch_size: int):\n",
    "        super().__init__()\n",
    "        self._base_dataset = base_dataset\n",
    "        self._user_batch_size = user_batch_size\n",
    "\n",
    "    @property\n",
    "    def users_set(self) -> torch.Tensor:\n",
    "        return self._base_dataset.users_set\n",
    "\n",
    "    @property\n",
    "    def items_set(self) -> torch.Tensor:\n",
    "        return self._base_dataset.items_set\n",
    "\n",
    "    @property\n",
    "    def ground_truth(self) -> torch.Tensor:\n",
    "        return self._base_dataset.ground_truth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users_set) // self._user_batch_size + 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.users_set.split(self._user_batch_size):\n",
    "            yield {\"u_id\": batch}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MFModelConfig:\n",
    "    n_users: int\n",
    "    n_items: int\n",
    "    emb_size: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    valid_size: float\n",
    "    batch_size: int\n",
    "    train_print_every: int\n",
    "    neg_sampl: int\n",
    "    lr: float\n",
    "    epochs: int\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, config: MFModelConfig):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(config.n_users, config.emb_size)\n",
    "        self.item_factors = nn.Embedding(config.n_items, config.emb_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.dot = DotProd()\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_factors = self.dropout(self.user_factors(x[\"u_id\"]))\n",
    "        item_factors = self.dropout(self.item_factors(x[\"i_id\"]))\n",
    "        return self.dot(user_factors, item_factors)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def recommend(self, x: dict[str, torch.Tensor]):\n",
    "        user_emb = self.user_factors.weight[x[\"u_id\"]]\n",
    "        item_emb = self.item_factors.weight\n",
    "        return torch.sigmoid(user_emb @ item_emb.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ratings_train\n",
    "\n",
    "unique_sessions = ratings_validation[\"session_id\"].unique()\n",
    "shuffled_sessions = np.random.permutation(unique_sessions)\n",
    "split_point = int(0.8*len(shuffled_sessions))\n",
    "X_valid_train = ratings_validation[ratings_validation[\"session_id\"].isin(shuffled_sessions[:split_point])]\n",
    "X_valid_valid = ratings_validation[ratings_validation[\"session_id\"].isin(shuffled_sessions[split_point:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFTrainer:\n",
    "    def __init__(self, model_config, train_config, dataset, device: \"torch.device\"):\n",
    "        self.model_config = model_config\n",
    "        self.train_config = train_config\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.datasets = self._init_datasets()\n",
    "        self.loaders = self._init_loaders()\n",
    "        self.model = self._init_model()\n",
    "        self.optimizer = self._init_optimizer()\n",
    "        self.criterion = self._init_criterion()\n",
    "        self.scheduler = self._init_scheduler()\n",
    "\n",
    "    @property\n",
    "    def _model_config(self) -> type:\n",
    "        return MFModelConfig\n",
    "\n",
    "    def _init_model(self) -> nn.Module:\n",
    "        model = MF(self.model_config).to(\n",
    "            self.device\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def _init_optimizer(self) -> torch.optim.Optimizer:\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.train_config.lr)\n",
    "\n",
    "    def _init_criterion(self) -> nn.Module:\n",
    "        return nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def _init_scheduler(self) -> Any:\n",
    "        return torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "    def _init_datasets(self) -> dict[str, Dataset]:\n",
    "        X_train, X_valid = self.dataset.data[\"relations\"]\n",
    "\n",
    "        train_dataset = MFDataset(\n",
    "            relations=X_train,\n",
    "            users=self.dataset.data[\"users\"],\n",
    "            items=self.dataset.data[\"items\"],\n",
    "            namings=self.dataset.namings,\n",
    "            neg_sampl=self.train_config.neg_sampl,\n",
    "        )\n",
    "        val_dataset = MFDataset(\n",
    "            relations=X_valid,\n",
    "            users=self.dataset.data[\"users\"],\n",
    "            items=self.dataset.data[\"items\"],\n",
    "            namings=self.dataset.namings,\n",
    "            neg_sampl=self.train_config.neg_sampl,\n",
    "        )\n",
    "\n",
    "        return {\"train\": train_dataset, \"val\": val_dataset}\n",
    "\n",
    "    def _init_loaders(self) -> dict[str, DataLoader]:\n",
    "        train_loader = DataLoader(self.datasets[\"train\"], batch_size=self.train_config.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(self.datasets[\"val\"], batch_size=self.train_config.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        return {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "    @torch.no_grad\n",
    "    def recommend_udf(self, batch: dict[str, torch.Tensor], model: nn.Module, n_items: int) -> torch.Tensor:\n",
    "        model.eval()\n",
    "        return model.recommend(batch)\n",
    "\n",
    "    def train(self, print_every: None | int = None) -> tuple[float, float]:\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        preds, ground_truths = [], []\n",
    "\n",
    "        for batch_idx, batch in enumerate(self.loaders[\"train\"]):\n",
    "            data = batch_dict_to_device(batch, self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, data[\"target\"])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            loss_item = loss.detach().cpu().item()\n",
    "\n",
    "            if print_every is not None and batch_idx % print_every == 0:\n",
    "                percentage = 100.0 * batch_idx / len(self.loaders[\"train\"])\n",
    "                print(f\"Train (Batch): [{batch_idx}/{len(self.loaders['train'])} ({percentage:.0f}%)] | Loss: {loss_item:.4f}\")\n",
    "\n",
    "            preds.append(output)\n",
    "            ground_truths.append(data[\"target\"])\n",
    "            train_loss += loss_item\n",
    "\n",
    "        train_loss /= len(self.loaders[\"train\"])\n",
    "\n",
    "        pred = torch.cat(preds, dim=0).detach().sigmoid().cpu().numpy()\n",
    "        ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
    "        train_roc_auc = float(roc_auc_score(ground_truth, pred))\n",
    "\n",
    "        print(f\"\\nTrain: Loss: {train_loss:.4f} | ROC AUC: {train_roc_auc:.4f}\")\n",
    "\n",
    "        return train_loss, train_roc_auc\n",
    "\n",
    "    def test(self) -> tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        test_loss = 0.0\n",
    "        preds, ground_truths = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(self.loaders[\"val\"]):\n",
    "                data = batch_dict_to_device(batch, self.device)\n",
    "\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, data[\"target\"])\n",
    "\n",
    "                preds.append(output)\n",
    "                ground_truths.append(data[\"target\"])\n",
    "                test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        pred = torch.cat(preds, dim=0).sigmoid().cpu().numpy()\n",
    "        ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "        test_roc_auc = float(roc_auc_score(ground_truth, pred))\n",
    "        test_loss /= len(self.loaders[\"val\"])\n",
    "\n",
    "        print(f\"Test: Loss: {test_loss:.4f} | ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "        return test_loss, test_roc_auc\n",
    "\n",
    "    def fit(self):\n",
    "        history = {\"train_loss\": [], \"train_roc_auc\": [], \"test_loss\": [], \"test_roc_auc\": []}\n",
    "        for epoch in tqdm(range(1, self.train_config.epochs + 1)):\n",
    "            train_loss, train_roc_auc = self.train(print_every=self.train_config.train_print_every)\n",
    "            test_loss, test_roc_auc = self.test()\n",
    "\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_roc_auc\"].append(train_roc_auc)\n",
    "            history[\"test_loss\"].append(test_loss)\n",
    "            history[\"test_roc_auc\"].append(test_roc_auc)\n",
    "\n",
    "        return history\n",
    "\n",
    "ds = SimpleNamespace(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    data={\n",
    "        \"relations\": (X_train[[\"session_id\", \"item_id\"]], X_valid_train[[\"session_id\", \"item_id\"]]),\n",
    "        \"users\": ratings[\"session_id\"],\n",
    "        \"items\": ratings[\"item_id\"],\n",
    "    },\n",
    "    namings={\"user\": \"session_id\", \"item\": \"item_id\"}\n",
    ")\n",
    "\n",
    "trainer = MFTrainer(\n",
    "    MFModelConfig(n_users=n_users, n_items=n_items, emb_size=8), \n",
    "    TrainConfig(valid_size=0.2, batch_size=4096, train_print_every=1000, neg_sampl=1, lr=1e-3, epochs=3), \n",
    "    dataset=ds, \n",
    "    device=torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Batch): [0/3801 (0%)] | Loss: 1.3102\n",
      "Train (Batch): [1000/3801 (26%)] | Loss: 1.1408\n",
      "Train (Batch): [2000/3801 (53%)] | Loss: 1.0034\n",
      "Train (Batch): [3000/3801 (79%)] | Loss: 0.9377\n",
      "\n",
      "Train: Loss: 1.0578 | ROC AUC: 0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [04:26<08:52, 266.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.9850 | ROC AUC: 0.4998\n",
      "Train (Batch): [0/3801 (0%)] | Loss: 0.9037\n",
      "Train (Batch): [1000/3801 (26%)] | Loss: 0.8660\n",
      "Train (Batch): [2000/3801 (53%)] | Loss: 0.8297\n",
      "Train (Batch): [3000/3801 (79%)] | Loss: 0.7923\n",
      "\n",
      "Train: Loss: 0.8312 | ROC AUC: 0.5036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [08:55<04:28, 268.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.8627 | ROC AUC: 0.5050\n",
      "Train (Batch): [0/3801 (0%)] | Loss: 0.7766\n",
      "Train (Batch): [1000/3801 (26%)] | Loss: 0.7481\n",
      "Train (Batch): [2000/3801 (53%)] | Loss: 0.7244\n",
      "Train (Batch): [3000/3801 (79%)] | Loss: 0.6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [12:53<06:26, 386.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 126\u001b[0m, in \u001b[0;36mMFTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m history \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_roc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_roc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_config\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 126\u001b[0m     train_loss, train_roc_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_print_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     test_loss, test_roc_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest()\n\u001b[1;32m    129\u001b[0m     history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[49], line 69\u001b[0m, in \u001b[0;36mMFTrainer.train\u001b[0;34m(self, print_every)\u001b[0m\n\u001b[1;32m     66\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     67\u001b[0m preds, ground_truths \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     70\u001b[0m     data \u001b[38;5;241m=\u001b[39m batch_dict_to_device(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/Projects/recsys/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/Projects/recsys/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/Projects/recsys/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/Projects/recsys/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[44], line 72\u001b[0m, in \u001b[0;36mMFDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     69\u001b[0m user \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     70\u001b[0m items \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m u_id \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neg_sampl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m i_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([items, approx_neg_sampl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_items, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neg_sampl)])\n\u001b[1;32m     74\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neg_sampl, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_interactions = trainer.loaders[\"train\"].dataset.ground_truth\n",
    "users_set = trainer.loaders[\"eval\"].dataset.users_set\n",
    "items_set = trainer.loaders[\"eval\"].dataset.items_set\n",
    "ground_truth = trainer.loaders[\"eval\"].dataset.ground_truth\n",
    "n_users = trainer.dataset.n_users\n",
    "n_items = trainer.dataset.n_items\n",
    "N_candid = 300\n",
    "\n",
    "\n",
    "recommendations = recommend_k(\n",
    "    partial(self.recommend_udf, model=trainer.model, n_items=len(items_set)),\n",
    "    trainer.loaders[\"eval\"],\n",
    "    N_candid,\n",
    "    device=trainer.device,\n",
    "    past_interactions=past_interactions,\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:17<00:00,  9.23it/s]\n"
     ]
    }
   ],
   "source": [
    "N_candid = 300\n",
    "\n",
    "recommendations = []\n",
    "for batch in tqdm(torch.split(user_embeddings_tensor, 1000)):\n",
    "    similarity = torch.matmul(batch, embeddings_tensor.T)\n",
    "    recommendations.append(similarity.topk(N_candid, dim=1).indices)\n",
    "recommendations = torch.vstack(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_items = ratings_train[[\"session_id\", 'item_id']].drop_duplicates()[\"item_id\"].value_counts()\n",
    "recommendations_cleora = pd.DataFrame({\"session_id\": user_embedding_series.index, \"candidates\": recommendations.numpy().tolist()})\n",
    "missing_indices = np.setdiff1d(np.arange(n_users), user_embedding_series.index)\n",
    "most_popular_list = most_popular_items.index[:N_candid].tolist()\n",
    "missing_recommendations_df = pd.DataFrame({\n",
    "    'session_id': missing_indices,\n",
    "    'candidates': [most_popular_list] * len(missing_indices)\n",
    "})\n",
    "recommendations_full = pd.concat([recommendations_cleora, missing_recommendations_df], axis=0).sort_values(\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = torch.from_numpy(ratings_validation[[\"session_id\", \"item_id\"]].values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_k_rel(rel, rel_sum, rel_mask) -> torch.Tensor:\n",
    "    return torch.mean(torch.sum(rel[rel_mask], dim=1) / rel_sum[rel_mask])\n",
    "\n",
    "\n",
    "def precision_k_rel(rel, rel_sum, rel_mask) -> torch.Tensor:\n",
    "    return torch.mean(torch.mean(rel[rel_mask], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.000000 | Precision@5: 0.089534 | Recall@5: 0.009315\n",
      "MAP@10: 0.000000 | Precision@10: 0.080695 | Recall@10: 0.016743\n",
      "MAP@50: 0.000000 | Precision@50: 0.054934 | Recall@50: 0.051867\n",
      "MAP@100: 0.000000 | Precision@100: 0.042858 | Recall@100: 0.079674\n",
      "MAP@200: 0.000000 | Precision@200: 0.032318 | Recall@200: 0.116187\n",
      "MAP@300: 0.000000 | Precision@300: 0.026903 | Recall@300: 0.142276\n"
     ]
    }
   ],
   "source": [
    "recommendations_tensor = torch.from_numpy(np.array(recommendations_full['candidates'].tolist()))\n",
    "users_idx = torch.from_numpy(recommendations_full['session_id'].values)\n",
    "\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = recommendations_tensor[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth, users_idx=users_idx, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {0:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies2 = movies.merge(movie_id_map, on=\"movieId\").drop([\"movieId\", \"title\"], axis=1)\n",
    "movies_genres_exploded = movies2[\"genres\"].str.split(\"|\").explode()\n",
    "genres_map = {genre:i for i, genre in enumerate(movies_genres_exploded.unique())}\n",
    "genres_one_hot = pd.get_dummies(movies_genres_exploded).astype(np.int8).groupby(level=0).sum()\n",
    "item_features = genres_one_hot.reset_index().rename(columns={'index': 'item_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47391</th>\n",
       "      <td>47391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47392</th>\n",
       "      <td>47392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47393</th>\n",
       "      <td>47393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47394</th>\n",
       "      <td>47394</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47395</th>\n",
       "      <td>47395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47396 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  (no genres listed)  Action  Adventure  Animation  Children  \\\n",
       "0            0                   0       0          1          1         1   \n",
       "1            1                   0       0          1          0         1   \n",
       "2            2                   0       0          0          0         0   \n",
       "3            3                   0       0          0          0         0   \n",
       "4            4                   0       0          0          0         0   \n",
       "...        ...                 ...     ...        ...        ...       ...   \n",
       "47391    47391                   0       0          0          0         0   \n",
       "47392    47392                   0       0          0          0         0   \n",
       "47393    47393                   1       0          0          0         0   \n",
       "47394    47394                   0       1          0          0         0   \n",
       "47395    47395                   0       0          0          0         0   \n",
       "\n",
       "       Comedy  Crime  Documentary  Drama  ...  Film-Noir  Horror  IMAX  \\\n",
       "0           1      0            0      0  ...          0       0     0   \n",
       "1           0      0            0      0  ...          0       0     0   \n",
       "2           1      0            0      0  ...          0       0     0   \n",
       "3           1      0            0      1  ...          0       0     0   \n",
       "4           1      0            0      0  ...          0       0     0   \n",
       "...       ...    ...          ...    ...  ...        ...     ...   ...   \n",
       "47391       0      0            1      0  ...          0       0     0   \n",
       "47392       0      1            0      0  ...          0       1     0   \n",
       "47393       0      0            0      0  ...          0       0     0   \n",
       "47394       1      0            0      0  ...          0       0     0   \n",
       "47395       1      0            0      1  ...          0       0     0   \n",
       "\n",
       "       Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0            0        0        0       0         0    0        0  \n",
       "1            0        0        0       0         0    0        0  \n",
       "2            0        0        1       0         0    0        0  \n",
       "3            0        0        1       0         0    0        0  \n",
       "4            0        0        0       0         0    0        0  \n",
       "...        ...      ...      ...     ...       ...  ...      ...  \n",
       "47391        0        0        0       0         0    0        0  \n",
       "47392        0        0        0       0         0    0        0  \n",
       "47393        0        0        0       0         0    0        0  \n",
       "47394        0        0        1       0         0    0        0  \n",
       "47395        0        0        0       0         0    0        0  \n",
       "\n",
       "[47396 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_56025/1608061395.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_categories_agg = ratings_train.groupby(\"session_id\").apply(get_categories_agg).reset_index()\n"
     ]
    }
   ],
   "source": [
    "user_features = pd.DataFrame({\"session_id\": range(n_users)})\n",
    "\n",
    "mean_ratings = ratings_train.groupby(\"session_id\")[\"rating\"].mean().reset_index(name=\"mean_rating\")\n",
    "average_mean_rating = mean_ratings[\"mean_rating\"].mean()\n",
    "user_features = user_features.merge(mean_ratings, on=\"session_id\", how=\"left\").fillna(average_mean_rating)\n",
    "\n",
    "def get_categories_agg(x):\n",
    "    return genres_one_hot.iloc[x[\"item_id\"]].sum(axis=0)\n",
    "\n",
    "user_categories_agg = ratings_train.groupby(\"session_id\").apply(get_categories_agg).reset_index()\n",
    "average_user_categories_agg = user_categories_agg.drop(\"session_id\", axis=1).mean(axis=0)\n",
    "\n",
    "categories_cols = user_categories_agg.drop(\"session_id\", axis=1).columns\n",
    "\n",
    "user_features = user_features.merge(user_categories_agg, on=\"session_id\", how=\"left\")\n",
    "user_features = user_features.fillna(average_user_categories_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.373333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.379310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162409</th>\n",
       "      <td>162409</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>8.900736</td>\n",
       "      <td>4.558981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316569</td>\n",
       "      <td>8.073843</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>3.88347</td>\n",
       "      <td>5.085948</td>\n",
       "      <td>17.452297</td>\n",
       "      <td>7.443396</td>\n",
       "      <td>15.15876</td>\n",
       "      <td>4.249665</td>\n",
       "      <td>1.510183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162410</th>\n",
       "      <td>162410</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>8.900736</td>\n",
       "      <td>4.558981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316569</td>\n",
       "      <td>8.073843</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>3.88347</td>\n",
       "      <td>5.085948</td>\n",
       "      <td>17.452297</td>\n",
       "      <td>7.443396</td>\n",
       "      <td>15.15876</td>\n",
       "      <td>4.249665</td>\n",
       "      <td>1.510183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162411</th>\n",
       "      <td>162411</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>8.900736</td>\n",
       "      <td>4.558981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316569</td>\n",
       "      <td>8.073843</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>3.88347</td>\n",
       "      <td>5.085948</td>\n",
       "      <td>17.452297</td>\n",
       "      <td>7.443396</td>\n",
       "      <td>15.15876</td>\n",
       "      <td>4.249665</td>\n",
       "      <td>1.510183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162412</th>\n",
       "      <td>162412</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>8.900736</td>\n",
       "      <td>4.558981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316569</td>\n",
       "      <td>8.073843</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>3.88347</td>\n",
       "      <td>5.085948</td>\n",
       "      <td>17.452297</td>\n",
       "      <td>7.443396</td>\n",
       "      <td>15.15876</td>\n",
       "      <td>4.249665</td>\n",
       "      <td>1.510183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162413</th>\n",
       "      <td>162413</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>8.900736</td>\n",
       "      <td>4.558981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316569</td>\n",
       "      <td>8.073843</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>3.88347</td>\n",
       "      <td>5.085948</td>\n",
       "      <td>17.452297</td>\n",
       "      <td>7.443396</td>\n",
       "      <td>15.15876</td>\n",
       "      <td>4.249665</td>\n",
       "      <td>1.510183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162414 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  mean_rating  (no genres listed)     Action  Adventure  \\\n",
       "0                0     4.416667            0.000000   3.000000   5.000000   \n",
       "1                1     4.373333            0.000000  12.000000   8.000000   \n",
       "2                2     4.379310            0.000000  16.000000  15.000000   \n",
       "3                3     4.250000            0.000000   7.000000   3.000000   \n",
       "4                4     4.500000            0.000000   6.000000   3.000000   \n",
       "...            ...          ...                 ...        ...        ...   \n",
       "162409      162409     4.284805            0.282191  12.037779   9.929843   \n",
       "162410      162410     4.284805            0.282191  12.037779   9.929843   \n",
       "162411      162411     4.284805            0.282191  12.037779   9.929843   \n",
       "162412      162412     4.284805            0.282191  12.037779   9.929843   \n",
       "162413      162413     4.284805            0.282191  12.037779   9.929843   \n",
       "\n",
       "        Animation  Children    Comedy      Crime  Documentary  ...  Film-Noir  \\\n",
       "0        5.000000   6.00000   8.00000   3.000000     2.000000  ...   1.000000   \n",
       "1        2.000000   8.00000  32.00000   7.000000     2.000000  ...   1.000000   \n",
       "2        5.000000  14.00000  46.00000  13.000000     4.000000  ...   1.000000   \n",
       "3        0.000000   2.00000  15.00000   4.000000     1.000000  ...   0.000000   \n",
       "4        1.000000   2.00000  16.00000   5.000000     3.000000  ...   0.000000   \n",
       "...           ...       ...       ...        ...          ...  ...        ...   \n",
       "162409   2.824066   5.44789  32.20178   8.900736     4.558981  ...   1.316569   \n",
       "162410   2.824066   5.44789  32.20178   8.900736     4.558981  ...   1.316569   \n",
       "162411   2.824066   5.44789  32.20178   8.900736     4.558981  ...   1.316569   \n",
       "162412   2.824066   5.44789  32.20178   8.900736     4.558981  ...   1.316569   \n",
       "162413   2.824066   5.44789  32.20178   8.900736     4.558981  ...   1.316569   \n",
       "\n",
       "          Horror      IMAX  Musical   Mystery    Romance    Sci-Fi  Thriller  \\\n",
       "0       0.000000  0.000000  5.00000  0.000000   4.000000  3.000000   6.00000   \n",
       "1       4.000000  1.000000  2.00000  4.000000  18.000000  6.000000  20.00000   \n",
       "2       4.000000  1.000000  2.00000  5.000000  27.000000  9.000000  22.00000   \n",
       "3       1.000000  0.000000  1.00000  3.000000  11.000000  3.000000   9.00000   \n",
       "4       2.000000  0.000000  1.00000  1.000000   9.000000  2.000000  10.00000   \n",
       "...          ...       ...      ...       ...        ...       ...       ...   \n",
       "162409  8.073843  0.337255  3.88347  5.085948  17.452297  7.443396  15.15876   \n",
       "162410  8.073843  0.337255  3.88347  5.085948  17.452297  7.443396  15.15876   \n",
       "162411  8.073843  0.337255  3.88347  5.085948  17.452297  7.443396  15.15876   \n",
       "162412  8.073843  0.337255  3.88347  5.085948  17.452297  7.443396  15.15876   \n",
       "162413  8.073843  0.337255  3.88347  5.085948  17.452297  7.443396  15.15876   \n",
       "\n",
       "             War   Western  \n",
       "0       1.000000  0.000000  \n",
       "1       1.000000  0.000000  \n",
       "2       5.000000  0.000000  \n",
       "3       1.000000  0.000000  \n",
       "4       0.000000  0.000000  \n",
       "...          ...       ...  \n",
       "162409  4.249665  1.510183  \n",
       "162410  4.249665  1.510183  \n",
       "162411  4.249665  1.510183  \n",
       "162412  4.249665  1.510183  \n",
       "162413  4.249665  1.510183  \n",
       "\n",
       "[162414 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel, rel_sum, rel_mask = recommendation_relevance(recommendations_tensor, ground_truth, users_idx=users_idx, n_users=n_users, n_items=n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indices = rel_mask.nonzero(as_tuple=True)[0]\n",
    "true_indices_2d = true_indices.repeat(N_candid, 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = torch.stack([true_indices_2d, recommendations_tensor[rel_mask], rel[rel_mask]], dim=-1)\n",
    "triples_list = [tuple(triple) for triple in triples.reshape(-1, 3).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(triples_list, columns=[\"session_id\", \"item_id\", \"label\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.merge(user_features).merge(item_features, on=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training users: 1705\n",
      "Number of testing users: 569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the users into training and testing sets\n",
    "train_users, test_users = train_test_split(df_features['session_id'].unique(), test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Number of training users: {len(train_users)}\")\n",
    "print(f\"Number of testing users: {len(test_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_features[df_features[\"session_id\"].isin(train_users)]\n",
    "test_df = df_features[df_features[\"session_id\"].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>(no genres listed)_x</th>\n",
       "      <th>Action_x</th>\n",
       "      <th>Adventure_x</th>\n",
       "      <th>Animation_x</th>\n",
       "      <th>Children_x</th>\n",
       "      <th>Comedy_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir_y</th>\n",
       "      <th>Horror_y</th>\n",
       "      <th>IMAX_y</th>\n",
       "      <th>Musical_y</th>\n",
       "      <th>Mystery_y</th>\n",
       "      <th>Romance_y</th>\n",
       "      <th>Sci-Fi_y</th>\n",
       "      <th>Thriller_y</th>\n",
       "      <th>War_y</th>\n",
       "      <th>Western_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30269</td>\n",
       "      <td>7788</td>\n",
       "      <td>0</td>\n",
       "      <td>3.944060</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>641.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30269</td>\n",
       "      <td>1814</td>\n",
       "      <td>0</td>\n",
       "      <td>3.944060</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>641.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30269</td>\n",
       "      <td>7934</td>\n",
       "      <td>0</td>\n",
       "      <td>3.944060</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>641.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30269</td>\n",
       "      <td>9233</td>\n",
       "      <td>0</td>\n",
       "      <td>3.944060</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>641.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30269</td>\n",
       "      <td>5929</td>\n",
       "      <td>0</td>\n",
       "      <td>3.944060</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>641.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682195</th>\n",
       "      <td>162413</td>\n",
       "      <td>23172</td>\n",
       "      <td>1</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682196</th>\n",
       "      <td>162413</td>\n",
       "      <td>1120</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682197</th>\n",
       "      <td>162413</td>\n",
       "      <td>13558</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682198</th>\n",
       "      <td>162413</td>\n",
       "      <td>19263</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682199</th>\n",
       "      <td>162413</td>\n",
       "      <td>3790</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511500 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  item_id  label  mean_rating  (no genres listed)_x  \\\n",
       "0            30269     7788      0     3.944060             25.000000   \n",
       "1            30269     1814      0     3.944060             25.000000   \n",
       "2            30269     7934      0     3.944060             25.000000   \n",
       "3            30269     9233      0     3.944060             25.000000   \n",
       "4            30269     5929      0     3.944060             25.000000   \n",
       "...            ...      ...    ...          ...                   ...   \n",
       "682195      162413    23172      1     4.284805              0.282191   \n",
       "682196      162413     1120      0     4.284805              0.282191   \n",
       "682197      162413    13558      0     4.284805              0.282191   \n",
       "682198      162413    19263      0     4.284805              0.282191   \n",
       "682199      162413     3790      0     4.284805              0.282191   \n",
       "\n",
       "          Action_x  Adventure_x  Animation_x  Children_x   Comedy_x  ...  \\\n",
       "0       251.000000   158.000000    55.000000    84.00000  641.00000  ...   \n",
       "1       251.000000   158.000000    55.000000    84.00000  641.00000  ...   \n",
       "2       251.000000   158.000000    55.000000    84.00000  641.00000  ...   \n",
       "3       251.000000   158.000000    55.000000    84.00000  641.00000  ...   \n",
       "4       251.000000   158.000000    55.000000    84.00000  641.00000  ...   \n",
       "...            ...          ...          ...         ...        ...  ...   \n",
       "682195   12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "682196   12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "682197   12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "682198   12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "682199   12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "\n",
       "        Film-Noir_y  Horror_y  IMAX_y  Musical_y  Mystery_y  Romance_y  \\\n",
       "0                 0         0       0          0          0          1   \n",
       "1                 0         0       0          1          0          1   \n",
       "2                 0         0       0          0          0          0   \n",
       "3                 0         0       0          0          0          0   \n",
       "4                 0         0       0          0          0          0   \n",
       "...             ...       ...     ...        ...        ...        ...   \n",
       "682195            0         1       0          0          0          0   \n",
       "682196            0         0       0          0          0          0   \n",
       "682197            0         1       0          0          0          0   \n",
       "682198            0         1       0          0          0          0   \n",
       "682199            0         0       0          0          0          0   \n",
       "\n",
       "        Sci-Fi_y  Thriller_y  War_y  Western_y  \n",
       "0              0           0      0          0  \n",
       "1              0           0      0          0  \n",
       "2              0           0      1          0  \n",
       "3              0           0      0          0  \n",
       "4              0           0      0          0  \n",
       "...          ...         ...    ...        ...  \n",
       "682195         0           0      0          0  \n",
       "682196         0           0      0          0  \n",
       "682197         1           1      0          0  \n",
       "682198         0           1      0          0  \n",
       "682199         0           1      0          0  \n",
       "\n",
       "[511500 rows x 44 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>(no genres listed)_x</th>\n",
       "      <th>Action_x</th>\n",
       "      <th>Adventure_x</th>\n",
       "      <th>Animation_x</th>\n",
       "      <th>Children_x</th>\n",
       "      <th>Comedy_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir_y</th>\n",
       "      <th>Horror_y</th>\n",
       "      <th>IMAX_y</th>\n",
       "      <th>Musical_y</th>\n",
       "      <th>Mystery_y</th>\n",
       "      <th>Romance_y</th>\n",
       "      <th>Sci-Fi_y</th>\n",
       "      <th>Thriller_y</th>\n",
       "      <th>War_y</th>\n",
       "      <th>Western_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>33497</td>\n",
       "      <td>1101</td>\n",
       "      <td>0</td>\n",
       "      <td>4.162011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>137.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>33497</td>\n",
       "      <td>6577</td>\n",
       "      <td>0</td>\n",
       "      <td>4.162011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>137.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>33497</td>\n",
       "      <td>7035</td>\n",
       "      <td>0</td>\n",
       "      <td>4.162011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>137.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>33497</td>\n",
       "      <td>23095</td>\n",
       "      <td>0</td>\n",
       "      <td>4.162011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>137.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>33497</td>\n",
       "      <td>8122</td>\n",
       "      <td>0</td>\n",
       "      <td>4.162011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>137.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679795</th>\n",
       "      <td>162405</td>\n",
       "      <td>23172</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679796</th>\n",
       "      <td>162405</td>\n",
       "      <td>1120</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679797</th>\n",
       "      <td>162405</td>\n",
       "      <td>13558</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679798</th>\n",
       "      <td>162405</td>\n",
       "      <td>19263</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679799</th>\n",
       "      <td>162405</td>\n",
       "      <td>3790</td>\n",
       "      <td>0</td>\n",
       "      <td>4.284805</td>\n",
       "      <td>0.282191</td>\n",
       "      <td>12.037779</td>\n",
       "      <td>9.929843</td>\n",
       "      <td>2.824066</td>\n",
       "      <td>5.44789</td>\n",
       "      <td>32.20178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170700 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  item_id  label  mean_rating  (no genres listed)_x  \\\n",
       "2400         33497     1101      0     4.162011              1.000000   \n",
       "2401         33497     6577      0     4.162011              1.000000   \n",
       "2402         33497     7035      0     4.162011              1.000000   \n",
       "2403         33497    23095      0     4.162011              1.000000   \n",
       "2404         33497     8122      0     4.162011              1.000000   \n",
       "...            ...      ...    ...          ...                   ...   \n",
       "679795      162405    23172      0     4.284805              0.282191   \n",
       "679796      162405     1120      0     4.284805              0.282191   \n",
       "679797      162405    13558      0     4.284805              0.282191   \n",
       "679798      162405    19263      0     4.284805              0.282191   \n",
       "679799      162405     3790      0     4.284805              0.282191   \n",
       "\n",
       "         Action_x  Adventure_x  Animation_x  Children_x   Comedy_x  ...  \\\n",
       "2400    31.000000    33.000000    11.000000    21.00000  137.00000  ...   \n",
       "2401    31.000000    33.000000    11.000000    21.00000  137.00000  ...   \n",
       "2402    31.000000    33.000000    11.000000    21.00000  137.00000  ...   \n",
       "2403    31.000000    33.000000    11.000000    21.00000  137.00000  ...   \n",
       "2404    31.000000    33.000000    11.000000    21.00000  137.00000  ...   \n",
       "...           ...          ...          ...         ...        ...  ...   \n",
       "679795  12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "679796  12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "679797  12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "679798  12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "679799  12.037779     9.929843     2.824066     5.44789   32.20178  ...   \n",
       "\n",
       "        Film-Noir_y  Horror_y  IMAX_y  Musical_y  Mystery_y  Romance_y  \\\n",
       "2400              0         0       0          0          1          0   \n",
       "2401              0         0       0          1          0          1   \n",
       "2402              0         0       0          0          0          0   \n",
       "2403              0         0       0          0          0          0   \n",
       "2404              0         0       0          0          1          0   \n",
       "...             ...       ...     ...        ...        ...        ...   \n",
       "679795            0         1       0          0          0          0   \n",
       "679796            0         0       0          0          0          0   \n",
       "679797            0         1       0          0          0          0   \n",
       "679798            0         1       0          0          0          0   \n",
       "679799            0         0       0          0          0          0   \n",
       "\n",
       "        Sci-Fi_y  Thriller_y  War_y  Western_y  \n",
       "2400           0           0      0          0  \n",
       "2401           0           0      0          0  \n",
       "2402           0           0      0          0  \n",
       "2403           0           1      0          0  \n",
       "2404           0           1      0          0  \n",
       "...          ...         ...    ...        ...  \n",
       "679795         0           0      0          0  \n",
       "679796         0           0      0          0  \n",
       "679797         1           1      0          0  \n",
       "679798         0           1      0          0  \n",
       "679799         0           1      0          0  \n",
       "\n",
       "[170700 rows x 44 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 14082, number of negative: 497418\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3416\n",
      "[LightGBM] [Info] Number of data points in the train set: 511500, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.027531 -> initscore=-3.564533\n",
      "[LightGBM] [Info] Start training from score -3.564533\n",
      "Test Log Loss: 0.168724\n",
      "Test Accuracy: 0.970410\n",
      "   session_id                                         candidates\n",
      "0       33497  [20371, 8690, 1047, 1051, 970, 851, 187, 566, ...\n",
      "1       36315  [22355, 22359, 23496, 7864, 7931, 7972, 7781, ...\n",
      "2       37164  [15814, 15797, 1039, 1046, 1044, 4202, 3034, 9...\n",
      "3       37495  [1039, 1044, 4202, 3034, 958, 970, 974, 1972, ...\n",
      "4       38144  [108, 970, 851, 15797, 1039, 1048, 1051, 1047,...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_56025/61832164.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col not in ['label']]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "# Train using a binary objective – during inference we'll use predict_proba\n",
    "model = lgb.LGBMClassifier(objective='binary', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use predict_proba to obtain real-valued scores\n",
    "y_pred_scores = model.predict_proba(X_test)[:, 1]\n",
    "loss = log_loss(y_test, y_pred_scores)\n",
    "# Convert scores to binary labels at threshold 0.5 for accuracy calculation\n",
    "accuracy = accuracy_score(y_test, (y_pred_scores > 0.5).astype(int))\n",
    "print(f\"Test Log Loss: {loss:.6f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.6f}\")\n",
    "\n",
    "def reranker(model, X_test, df):\n",
    "    \"\"\"\n",
    "    Predict scores for each candidate using the trained model.\n",
    "    Groups items by session_id and sorts item_ids in descending order.\n",
    "    Returns a dataframe with session_id and the ranked candidates as a list.\n",
    "    \"\"\"\n",
    "    # Get the real valued scores\n",
    "    scores = model.predict_proba(X_test)[:, 1]\n",
    "    df = df.copy()\n",
    "    df['score'] = scores\n",
    "    # Group by session_id and sort items in descending order based on their score\n",
    "    reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n",
    "    return reranked\n",
    "\n",
    "# Example usage:\n",
    "reranked_df = reranker(model, X_test, test_df)\n",
    "print(reranked_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33497</td>\n",
       "      <td>[20371, 8690, 1047, 1051, 970, 851, 187, 566, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36315</td>\n",
       "      <td>[22355, 22359, 23496, 7864, 7931, 7972, 7781, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37164</td>\n",
       "      <td>[15814, 15797, 1039, 1046, 1044, 4202, 3034, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37495</td>\n",
       "      <td>[1039, 1044, 4202, 3034, 958, 970, 974, 1972, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38144</td>\n",
       "      <td>[108, 970, 851, 15797, 1039, 1048, 1051, 1047,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>162384</td>\n",
       "      <td>[13219, 9834, 185, 5613, 2363, 6804, 19425, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>162385</td>\n",
       "      <td>[13219, 9834, 185, 5613, 2363, 6804, 19425, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>162391</td>\n",
       "      <td>[13219, 9834, 185, 2363, 5613, 19425, 6804, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>162403</td>\n",
       "      <td>[13219, 9834, 5613, 185, 6804, 19425, 166, 981...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>162405</td>\n",
       "      <td>[13219, 9834, 5613, 185, 6804, 19425, 166, 981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     session_id                                         candidates\n",
       "0         33497  [20371, 8690, 1047, 1051, 970, 851, 187, 566, ...\n",
       "1         36315  [22355, 22359, 23496, 7864, 7931, 7972, 7781, ...\n",
       "2         37164  [15814, 15797, 1039, 1046, 1044, 4202, 3034, 9...\n",
       "3         37495  [1039, 1044, 4202, 3034, 958, 970, 974, 1972, ...\n",
       "4         38144  [108, 970, 851, 15797, 1039, 1048, 1051, 1047,...\n",
       "..          ...                                                ...\n",
       "564      162384  [13219, 9834, 185, 5613, 2363, 6804, 19425, 27...\n",
       "565      162385  [13219, 9834, 185, 5613, 2363, 6804, 19425, 27...\n",
       "566      162391  [13219, 9834, 185, 2363, 5613, 19425, 6804, 10...\n",
       "567      162403  [13219, 9834, 5613, 185, 6804, 19425, 166, 981...\n",
       "568      162405  [13219, 9834, 5613, 185, 6804, 19425, 166, 981...\n",
       "\n",
       "[569 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_full_reranked = recommendations_full\n",
    "recommendations_full_reranked = recommendations_full_reranked[~recommendations_full_reranked[\"session_id\"].isin(test_users)]\n",
    "recommendations_full_reranked = pd.concat([recommendations_full_reranked,reranked_df]).sort_values(by=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_validation2 = ratings_validation[ratings_validation[\"session_id\"].isin(test_users)]\n",
    "ground_truth = torch.from_numpy(ratings_validation2[[\"session_id\", \"item_id\"]].values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.000000 | Precision@5: 0.083304 | Recall@5: 0.008211\n",
      "MAP@10: 0.000000 | Precision@10: 0.076098 | Recall@10: 0.015451\n",
      "MAP@50: 0.000000 | Precision@50: 0.051810 | Recall@50: 0.050152\n",
      "MAP@100: 0.000000 | Precision@100: 0.040650 | Recall@100: 0.082717\n",
      "MAP@200: 0.000000 | Precision@200: 0.030351 | Recall@200: 0.110737\n",
      "MAP@300: 0.000000 | Precision@300: 0.025021 | Recall@300: 0.131867\n"
     ]
    }
   ],
   "source": [
    "recommendations_tensor = torch.from_numpy(np.array(recommendations_full['candidates'].tolist()))\n",
    "users_idx = torch.from_numpy(recommendations_full['session_id'].values)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = recommendations_tensor[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth, users_idx=users_idx, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {0:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.000000 | Precision@5: 0.086116 | Recall@5: 0.009465\n",
      "MAP@10: 0.000000 | Precision@10: 0.083128 | Recall@10: 0.017697\n",
      "MAP@50: 0.000000 | Precision@50: 0.054060 | Recall@50: 0.055579\n",
      "MAP@100: 0.000000 | Precision@100: 0.042935 | Recall@100: 0.084544\n",
      "MAP@200: 0.000000 | Precision@200: 0.032452 | Recall@200: 0.116838\n",
      "MAP@300: 0.000000 | Precision@300: 0.025021 | Recall@300: 0.131867\n"
     ]
    }
   ],
   "source": [
    "recommendations_tensor = torch.from_numpy(np.array(recommendations_full_reranked['candidates'].tolist()))\n",
    "users_idx = torch.from_numpy(recommendations_full_reranked['session_id'].values)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = recommendations_tensor[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth, users_idx=users_idx, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {0:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
