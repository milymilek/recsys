{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IPython\n",
    "from pathlib import Path\n",
    "import os\n",
    "locals = IPython.extract_module_locals() # type: ignore\n",
    "notebook_name = \"/\".join(locals[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "os.chdir(Path(notebook_name).parent.parent.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 22:59:19,138 - recsys.utils - INFO - Setting seed to 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from recsys.evaluation.metrics import map_k, precision_k, recall_k\n",
    "from recsys.evaluation.evaluation import recommendation_relevance\n",
    "from recsys.data.utils import filter_set\n",
    "from recsys.utils import create_log_dir, load_model, save_model, set_seed\n",
    "\n",
    "SEED = 0\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\".data/movielens/base\")\n",
    "\n",
    "movies = pd.read_csv(base_path / \"movies.csv\")\n",
    "links = pd.read_csv(base_path / \"links.csv\")\n",
    "tags = pd.read_csv(base_path / \"tags.csv\")\n",
    "\n",
    "intermediate_path = Path(\".data/movielens/intermediate/1\")\n",
    "\n",
    "ratings = pd.read_parquet(intermediate_path / \"ratings.parquet\")\n",
    "ratings_train = pd.read_parquet(intermediate_path / \"ratings_train.parquet\")\n",
    "ratings_validation = pd.read_parquet(intermediate_path / \"ratings_validation.parquet\")\n",
    "user_id_map = pd.read_parquet(intermediate_path / \"user_id_map.parquet\")\n",
    "movie_id_map = pd.read_parquet(intermediate_path / \"movie_id_map.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162414 47396 15630129\n"
     ]
    }
   ],
   "source": [
    "n_users = user_id_map[\"userId\"].nunique()\n",
    "n_items = movie_id_map['movieId'].nunique()\n",
    "\n",
    "print(n_users, n_items, ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from functools import cached_property\n",
    "from typing import Any\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    u_id = torch.cat([x[\"u_id\"] for x in batch])\n",
    "    i_id = torch.cat([x[\"i_id\"] for x in batch])\n",
    "    target = torch.cat([x[\"target\"] for x in batch])\n",
    "    return {\"u_id\": u_id, \"i_id\": i_id, \"target\": target}\n",
    "\n",
    "\n",
    "def eval_collate_fn(batch):\n",
    "    u_id = torch.cat([x[\"u_id\"] for x in batch])\n",
    "    return {\"u_id\": u_id}\n",
    "\n",
    "\n",
    "def approx_neg_sampl(n_items: int, neg_sampl: int) -> torch.Tensor:\n",
    "    return torch.randint(low=0, high=n_items, size=(neg_sampl,), dtype=torch.int32)\n",
    "\n",
    "\n",
    "def batch_dict_to_device(batch: dict[str, Any], device: torch.device) -> dict[str, Any]:\n",
    "    return {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "\n",
    "class DotProd(nn.Module):\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(x * y, dim=1)\n",
    "\n",
    "\n",
    "class MFDataset(Dataset):\n",
    "    def __init__(self, relations: pd.DataFrame, users: pd.DataFrame, items: pd.DataFrame, namings: dict[str, str], neg_sampl: int = 5):\n",
    "        self._df = torch.from_numpy(relations.values).to(torch.int32)\n",
    "        self._users = torch.from_numpy(users.unique()).to(torch.float32)\n",
    "        self._items = torch.from_numpy(items.unique()).to(torch.float32)\n",
    "        self._neg_sampl = neg_sampl\n",
    "\n",
    "    @property\n",
    "    def _n_users(self) -> int:\n",
    "        return len(self._users)\n",
    "\n",
    "    @property\n",
    "    def _n_items(self) -> int:\n",
    "        return len(self._items)\n",
    "\n",
    "    @cached_property\n",
    "    def users_set(self) -> torch.Tensor:\n",
    "        return torch.arange(self._n_users, dtype=torch.int32)\n",
    "\n",
    "    @cached_property\n",
    "    def items_set(self) -> torch.Tensor:\n",
    "        return torch.arange(self._n_items, dtype=torch.int32)\n",
    "\n",
    "    @cached_property\n",
    "    def ground_truth(self) -> torch.Tensor:\n",
    "        return self._df.T\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict[str, Any]:\n",
    "        row = self._df[idx]\n",
    "        user = row[0].unsqueeze(0)\n",
    "        items = row[1].unsqueeze(0)\n",
    "\n",
    "        u_id = user.repeat(self._neg_sampl + 1)\n",
    "        i_id = torch.cat([items, approx_neg_sampl(self._n_items, self._neg_sampl)])\n",
    "        target = torch.tensor([1.0] + [0.0] * self._neg_sampl, dtype=torch.float)\n",
    "\n",
    "        return {\"u_id\": u_id, \"i_id\": i_id, \"target\": target}\n",
    "\n",
    "\n",
    "class MFEvalDataset(IterableDataset):\n",
    "    def __init__(self, base_dataset: MFDataset, user_batch_size: int):\n",
    "        super().__init__()\n",
    "        self._base_dataset = base_dataset\n",
    "        self._user_batch_size = user_batch_size\n",
    "\n",
    "    @property\n",
    "    def users_set(self) -> torch.Tensor:\n",
    "        return self._base_dataset.users_set\n",
    "\n",
    "    @property\n",
    "    def items_set(self) -> torch.Tensor:\n",
    "        return self._base_dataset.items_set\n",
    "\n",
    "    @property\n",
    "    def ground_truth(self) -> torch.Tensor:\n",
    "        return self._base_dataset.ground_truth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users_set) // self._user_batch_size + 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.users_set.split(self._user_batch_size):\n",
    "            yield {\"u_id\": batch}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MFModelConfig:\n",
    "    n_users: int\n",
    "    n_items: int\n",
    "    emb_size: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    valid_size: float\n",
    "    batch_size: int\n",
    "    train_print_every: int\n",
    "    eval_batch_size: int\n",
    "    eval_user_batch_size: int\n",
    "    neg_sampl: int\n",
    "    lr: float\n",
    "    epochs: int\n",
    "\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, config: MFModelConfig):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(config.n_users, config.emb_size)\n",
    "        self.item_factors = nn.Embedding(config.n_items, config.emb_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.dot = DotProd()\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_factors = self.dropout(self.user_factors(x[\"u_id\"]))\n",
    "        item_factors = self.dropout(self.item_factors(x[\"i_id\"]))\n",
    "        return self.dot(user_factors, item_factors)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def recommend(self, x: dict[str, torch.Tensor]):\n",
    "        user_emb = self.user_factors.weight[x[\"u_id\"]]\n",
    "        item_emb = self.item_factors.weight\n",
    "        return torch.sigmoid(user_emb @ item_emb.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation-training users: 2456\n",
      "Number of validation-validation users: 1053\n"
     ]
    }
   ],
   "source": [
    "X_train = ratings_train\n",
    "\n",
    "train_users, test_users = train_test_split(ratings_validation['session_id'].unique(), test_size=0.3, random_state=0)\n",
    "\n",
    "X_valid_train = ratings_validation[ratings_validation[\"session_id\"].isin(train_users)]\n",
    "X_valid_valid = ratings_validation[ratings_validation[\"session_id\"].isin(test_users)]\n",
    "\n",
    "print(f\"Number of validation-training users: {len(train_users)}\")\n",
    "print(f\"Number of validation-validation users: {len(test_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFTrainer:\n",
    "    def __init__(self, model_config, train_config, dataset, device: \"torch.device\"):\n",
    "        self.model_config = model_config\n",
    "        self.train_config = train_config\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.datasets = self._init_datasets()\n",
    "        self.loaders = self._init_loaders()\n",
    "        self.model = self._init_model()\n",
    "        self.optimizer = self._init_optimizer()\n",
    "        self.criterion = self._init_criterion()\n",
    "        self.scheduler = self._init_scheduler()\n",
    "\n",
    "    @property\n",
    "    def _model_config(self) -> type:\n",
    "        return MFModelConfig\n",
    "\n",
    "    def _init_model(self) -> nn.Module:\n",
    "        model = MF(self.model_config).to(\n",
    "            self.device\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def _init_optimizer(self) -> torch.optim.Optimizer:\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.train_config.lr)\n",
    "\n",
    "    def _init_criterion(self) -> nn.Module:\n",
    "        return nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def _init_scheduler(self) -> Any:\n",
    "        return torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "    def _init_datasets(self) -> dict[str, Dataset]:\n",
    "        X_train, X_valid = self.dataset.data[\"relations\"]\n",
    "\n",
    "        train_dataset = MFDataset(\n",
    "            relations=X_train,\n",
    "            users=self.dataset.data[\"users\"],\n",
    "            items=self.dataset.data[\"items\"],\n",
    "            namings=self.dataset.namings,\n",
    "            neg_sampl=self.train_config.neg_sampl,\n",
    "        )\n",
    "        val_dataset = MFDataset(\n",
    "            relations=X_valid,\n",
    "            users=self.dataset.data[\"users\"],\n",
    "            items=self.dataset.data[\"items\"],\n",
    "            namings=self.dataset.namings,\n",
    "            neg_sampl=self.train_config.neg_sampl,\n",
    "        )\n",
    "        eval_dataset = MFEvalDataset(\n",
    "            base_dataset=val_dataset,\n",
    "            user_batch_size=self.train_config.eval_user_batch_size,\n",
    "        )\n",
    "\n",
    "        return {\"train\": train_dataset, \"val\": val_dataset, \"eval\": eval_dataset}\n",
    "\n",
    "    def _init_loaders(self) -> dict[str, DataLoader]:\n",
    "        train_loader = DataLoader(self.datasets[\"train\"], batch_size=self.train_config.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(self.datasets[\"val\"], batch_size=self.train_config.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        eval_loader = DataLoader(\n",
    "            self.datasets[\"eval\"], batch_size=self.train_config.eval_batch_size, shuffle=False, collate_fn=eval_collate_fn, drop_last=False\n",
    "        )\n",
    "\n",
    "        return {\"train\": train_loader, \"val\": val_loader, \"eval\": eval_loader}\n",
    "\n",
    "    @torch.no_grad\n",
    "    def recommend_udf(self, batch: dict[str, torch.Tensor], model: MF, n_items: int) -> torch.Tensor:\n",
    "        model.eval()\n",
    "        return model.recommend(batch)\n",
    "\n",
    "    def train(self, print_every: None | int = None) -> tuple[float, float]:\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        preds, ground_truths = [], []\n",
    "\n",
    "        for batch_idx, batch in enumerate(self.loaders[\"train\"]):\n",
    "            data = batch_dict_to_device(batch, self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, data[\"target\"])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            loss_item = loss.detach().cpu().item()\n",
    "\n",
    "            if print_every is not None and batch_idx % print_every == 0:\n",
    "                percentage = 100.0 * batch_idx / len(self.loaders[\"train\"])\n",
    "                print(f\"Train (Batch): [{batch_idx}/{len(self.loaders['train'])} ({percentage:.0f}%)] | Loss: {loss_item:.4f}\")\n",
    "\n",
    "            preds.append(output)\n",
    "            ground_truths.append(data[\"target\"])\n",
    "            train_loss += loss_item\n",
    "\n",
    "        train_loss /= len(self.loaders[\"train\"])\n",
    "\n",
    "        pred = torch.cat(preds, dim=0).detach().sigmoid().cpu().numpy()\n",
    "        ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
    "        train_roc_auc = float(roc_auc_score(ground_truth, pred))\n",
    "\n",
    "        print(f\"\\nTrain: Loss: {train_loss:.4f} | ROC AUC: {train_roc_auc:.4f}\")\n",
    "\n",
    "        return train_loss, train_roc_auc\n",
    "\n",
    "    def test(self) -> tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        test_loss = 0.0\n",
    "        preds, ground_truths = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(self.loaders[\"val\"]):\n",
    "                data = batch_dict_to_device(batch, self.device)\n",
    "\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, data[\"target\"])\n",
    "\n",
    "                preds.append(output)\n",
    "                ground_truths.append(data[\"target\"])\n",
    "                test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        pred = torch.cat(preds, dim=0).sigmoid().cpu().numpy()\n",
    "        ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "        test_roc_auc = float(roc_auc_score(ground_truth, pred))\n",
    "        test_loss /= len(self.loaders[\"val\"])\n",
    "\n",
    "        print(f\"Test: Loss: {test_loss:.4f} | ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "        return test_loss, test_roc_auc\n",
    "\n",
    "    def fit(self):\n",
    "        history = {\"train_loss\": [], \"train_roc_auc\": [], \"test_loss\": [], \"test_roc_auc\": []}\n",
    "        for epoch in tqdm(range(1, self.train_config.epochs + 1)):\n",
    "            train_loss, train_roc_auc = self.train(print_every=self.train_config.train_print_every)\n",
    "            test_loss, test_roc_auc = self.test()\n",
    "\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_roc_auc\"].append(train_roc_auc)\n",
    "            history[\"test_loss\"].append(test_loss)\n",
    "            history[\"test_roc_auc\"].append(test_roc_auc)\n",
    "\n",
    "        return history\n",
    "\n",
    "ds = SimpleNamespace(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    data={\n",
    "        \"relations\": (ratings_train[[\"session_id\", \"item_id\"]], ratings_validation[[\"session_id\", \"item_id\"]]),\n",
    "        \"users\": ratings[\"session_id\"],\n",
    "        \"items\": ratings[\"item_id\"],\n",
    "    },\n",
    "    namings={\"user\": \"session_id\", \"item\": \"item_id\"}\n",
    ")\n",
    "\n",
    "trainer = MFTrainer(\n",
    "    MFModelConfig(n_users=n_users, n_items=n_items, emb_size=8), \n",
    "    TrainConfig(valid_size=0.2, batch_size=4096, train_print_every=1000, neg_sampl=1, lr=1e-3, epochs=7, eval_user_batch_size=1000, eval_batch_size=1), \n",
    "    dataset=ds, \n",
    "    device=torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = create_log_dir(trainer.model)\n",
    "# save_model(trainer.model, log_dir / \"weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 22:59:20,219 - recsys.utils - INFO - Loading model <class '__main__.MF'> from .runs/MF/2025-02-16_13-40-50/weights.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.model = load_model(MF, Path(\".runs/MF/2025-02-16_13-40-50/weights.pth\"), {\"config\": trainer.model_config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_k_rel(rel, rel_sum, rel_mask) -> torch.Tensor:\n",
    "    return torch.mean(torch.sum(rel[rel_mask], dim=1) / rel_sum[rel_mask])\n",
    "\n",
    "\n",
    "def precision_k_rel(rel, rel_sum, rel_mask) -> torch.Tensor:\n",
    "    return torch.mean(torch.mean(rel[rel_mask], dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year_month</th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15513469</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-28 07:22:42</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>15726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15519958</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-30 03:37:54</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>22740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15522291</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-01 05:01:17</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>21011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15534185</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-07 04:50:03</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>46792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15540795</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-10 04:28:11</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>41545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630123</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-21 09:10:06</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630124</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-21 09:10:45</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>19425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630125</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-21 09:11:19</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>31049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630126</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-21 09:12:13</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>45653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630128</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-21 09:15:03</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>25130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133162 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating           timestamp year_month  session_id  item_id\n",
       "15513469     4.0 2019-09-28 07:22:42    2019-09       30269    15726\n",
       "15519958     4.0 2019-09-30 03:37:54    2019-09       30269    22740\n",
       "15522291     3.5 2019-10-01 05:01:17    2019-10       30269    21011\n",
       "15534185     3.5 2019-10-07 04:50:03    2019-10       30269    46792\n",
       "15540795     3.5 2019-10-10 04:28:11    2019-10       30269    41545\n",
       "...          ...                 ...        ...         ...      ...\n",
       "15630123     4.5 2019-11-21 09:10:06    2019-11      162413     9818\n",
       "15630124     4.5 2019-11-21 09:10:45    2019-11      162413    19425\n",
       "15630125     4.0 2019-11-21 09:11:19    2019-11      162413    31049\n",
       "15630126     4.0 2019-11-21 09:12:13    2019-11      162413    45653\n",
       "15630128     4.5 2019-11-21 09:15:03    2019-11      162413    25130\n",
       "\n",
       "[133162 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year_month</th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15513469</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-28 07:22:42</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>15726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15519958</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-30 03:37:54</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>22740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15522291</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-01 05:01:17</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>21011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15534185</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-07 04:50:03</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>46792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15540795</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-10 04:28:11</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>41545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630042</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-11-21 05:29:25</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162412</td>\n",
       "      <td>9396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630043</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-11-21 05:30:37</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162412</td>\n",
       "      <td>20743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630045</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-11-21 05:33:35</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162412</td>\n",
       "      <td>38426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630046</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-11-21 05:34:22</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162412</td>\n",
       "      <td>4976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630047</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-11-21 05:34:45</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162412</td>\n",
       "      <td>7044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94029 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating           timestamp year_month  session_id  item_id\n",
       "15513469     4.0 2019-09-28 07:22:42    2019-09       30269    15726\n",
       "15519958     4.0 2019-09-30 03:37:54    2019-09       30269    22740\n",
       "15522291     3.5 2019-10-01 05:01:17    2019-10       30269    21011\n",
       "15534185     3.5 2019-10-07 04:50:03    2019-10       30269    46792\n",
       "15540795     3.5 2019-10-10 04:28:11    2019-10       30269    41545\n",
       "...          ...                 ...        ...         ...      ...\n",
       "15630042     3.5 2019-11-21 05:29:25    2019-11      162412     9396\n",
       "15630043     3.5 2019-11-21 05:30:37    2019-11      162412    20743\n",
       "15630045     3.5 2019-11-21 05:33:35    2019-11      162412    38426\n",
       "15630046     3.5 2019-11-21 05:34:22    2019-11      162412     4976\n",
       "15630047     3.5 2019-11-21 05:34:45    2019-11      162412     7044\n",
       "\n",
       "[94029 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year_month</th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15498286</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-22 18:58:00</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30362</td>\n",
       "      <td>38346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15498517</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-09-22 20:01:58</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30362</td>\n",
       "      <td>35041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15517387</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-09-29 15:08:52</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30362</td>\n",
       "      <td>3896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15563066</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-10-20 15:42:19</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30362</td>\n",
       "      <td>41030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15520324</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-09-30 08:47:38</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30441</td>\n",
       "      <td>42737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630123</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-21 09:10:06</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630124</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-21 09:10:45</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>19425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630125</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-21 09:11:19</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>31049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630126</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-21 09:12:13</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>45653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630128</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-21 09:15:03</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>162413</td>\n",
       "      <td>25130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39133 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating           timestamp year_month  session_id  item_id\n",
       "15498286     4.0 2019-09-22 18:58:00    2019-09       30362    38346\n",
       "15498517     5.0 2019-09-22 20:01:58    2019-09       30362    35041\n",
       "15517387     4.5 2019-09-29 15:08:52    2019-09       30362     3896\n",
       "15563066     4.5 2019-10-20 15:42:19    2019-10       30362    41030\n",
       "15520324     3.5 2019-09-30 08:47:38    2019-09       30441    42737\n",
       "...          ...                 ...        ...         ...      ...\n",
       "15630123     4.5 2019-11-21 09:10:06    2019-11      162413     9818\n",
       "15630124     4.5 2019-11-21 09:10:45    2019-11      162413    19425\n",
       "15630125     4.0 2019-11-21 09:11:19    2019-11      162413    31049\n",
       "15630126     4.0 2019-11-21 09:12:13    2019-11      162413    45653\n",
       "15630128     4.5 2019-11-21 09:15:03    2019-11      162413    25130\n",
       "\n",
       "[39133 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:08<00:00, 20.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from recsys.evaluation.prediction import recommend_k\n",
    "from functools import partial\n",
    "\n",
    "past_interactions = trainer.loaders[\"train\"].dataset.ground_truth\n",
    "N_candid = 300\n",
    "\n",
    "recommendations = recommend_k(\n",
    "    partial(trainer.recommend_udf, model=trainer.model, n_items=None),\n",
    "    trainer.loaders[\"eval\"],\n",
    "    N_candid,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    past_interactions=past_interactions,\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([162414, 300])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_filtered_valid_full = filter_set(ratings_validation, ratings_train, user_col=\"session_id\", item_col=\"item_id\")\n",
    "_filtered_valid_train = filter_set(X_valid_train, ratings_train, user_col=\"session_id\", item_col=\"item_id\")\n",
    "_filtered_valid_valid = filter_set(X_valid_valid, ratings_train, user_col=\"session_id\", item_col=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year_month</th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15513469</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-28 07:22:42</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>15726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15519958</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-30 03:37:54</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>22740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15522291</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-01 05:01:17</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>21011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15540795</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-10 04:28:11</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>41545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15542745</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-10-11 05:09:54</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>38630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588119</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-02 03:59:45</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588120</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-02 04:00:03</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588122</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-02 04:00:08</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588124</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-02 04:00:44</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588126</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-02 04:01:10</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>7317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34968 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating           timestamp year_month  session_id  item_id\n",
       "15513469     4.0 2019-09-28 07:22:42    2019-09       30269    15726\n",
       "15519958     4.0 2019-09-30 03:37:54    2019-09       30269    22740\n",
       "15522291     3.5 2019-10-01 05:01:17    2019-10       30269    21011\n",
       "15540795     3.5 2019-10-10 04:28:11    2019-10       30269    41545\n",
       "15542745     4.0 2019-10-11 05:09:54    2019-10       30269    38630\n",
       "...          ...                 ...        ...         ...      ...\n",
       "15588119     4.0 2019-11-02 03:59:45    2019-11      161494     1314\n",
       "15588120     4.5 2019-11-02 04:00:03    2019-11      161494     1062\n",
       "15588122     4.5 2019-11-02 04:00:08    2019-11      161494     1122\n",
       "15588124     4.0 2019-11-02 04:00:44    2019-11      161494      466\n",
       "15588126     4.0 2019-11-02 04:01:10    2019-11      161494     7317\n",
       "\n",
       "[34968 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filtered_valid_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filtered_valid_full.session_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year_month</th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15513469</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-28 07:22:42</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>15726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15519958</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-30 03:37:54</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30269</td>\n",
       "      <td>22740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15522291</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-01 05:01:17</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>21011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15540795</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-10-10 04:28:11</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>41545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15542745</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-10-11 05:09:54</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30269</td>\n",
       "      <td>38630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588119</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-02 03:59:45</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588120</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-02 04:00:03</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588122</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-11-02 04:00:08</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588124</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-02 04:00:44</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588126</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-11-02 04:01:10</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>161494</td>\n",
       "      <td>7317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25789 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating           timestamp year_month  session_id  item_id\n",
       "15513469     4.0 2019-09-28 07:22:42    2019-09       30269    15726\n",
       "15519958     4.0 2019-09-30 03:37:54    2019-09       30269    22740\n",
       "15522291     3.5 2019-10-01 05:01:17    2019-10       30269    21011\n",
       "15540795     3.5 2019-10-10 04:28:11    2019-10       30269    41545\n",
       "15542745     4.0 2019-10-11 05:09:54    2019-10       30269    38630\n",
       "...          ...                 ...        ...         ...      ...\n",
       "15588119     4.0 2019-11-02 03:59:45    2019-11      161494     1314\n",
       "15588120     4.5 2019-11-02 04:00:03    2019-11      161494     1062\n",
       "15588122     4.5 2019-11-02 04:00:08    2019-11      161494     1122\n",
       "15588124     4.0 2019-11-02 04:00:44    2019-11      161494      466\n",
       "15588126     4.0 2019-11-02 04:01:10    2019-11      161494     7317\n",
       "\n",
       "[25789 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filtered_valid_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filtered_valid_train.session_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year_month</th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15498286</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-22 18:58:00</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30362</td>\n",
       "      <td>38346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15498517</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-09-22 20:01:58</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30362</td>\n",
       "      <td>35041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15517387</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-09-29 15:08:52</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30362</td>\n",
       "      <td>3896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15563066</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-10-20 15:42:19</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>30362</td>\n",
       "      <td>41030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15520324</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2019-09-30 08:47:38</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>30441</td>\n",
       "      <td>42737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15556645</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-10-16 20:55:30</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>161478</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15499248</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-09-23 00:22:06</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>161489</td>\n",
       "      <td>6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15499262</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-23 00:27:17</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>161489</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15499263</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-09-23 00:28:26</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>161489</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15499265</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-09-23 00:29:56</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>161489</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9179 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating           timestamp year_month  session_id  item_id\n",
       "15498286     4.0 2019-09-22 18:58:00    2019-09       30362    38346\n",
       "15498517     5.0 2019-09-22 20:01:58    2019-09       30362    35041\n",
       "15517387     4.5 2019-09-29 15:08:52    2019-09       30362     3896\n",
       "15563066     4.5 2019-10-20 15:42:19    2019-10       30362    41030\n",
       "15520324     3.5 2019-09-30 08:47:38    2019-09       30441    42737\n",
       "...          ...                 ...        ...         ...      ...\n",
       "15556645     4.5 2019-10-16 20:55:30    2019-10      161478     2363\n",
       "15499248     4.5 2019-09-23 00:22:06    2019-09      161489     6686\n",
       "15499262     4.0 2019-09-23 00:27:17    2019-09      161489      167\n",
       "15499263     4.0 2019-09-23 00:28:26    2019-09      161489     1102\n",
       "15499265     4.5 2019-09-23 00:29:56    2019-09      161489      107\n",
       "\n",
       "[9179 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filtered_valid_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_filtered_valid_valid.session_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.034342 | Precision@5: 0.030072 | Recall@5: 0.012192\n",
      "MAP@10: 0.030905 | Precision@10: 0.025935 | Recall@10: 0.020335\n",
      "MAP@50: 0.023086 | Precision@50: 0.018234 | Recall@50: 0.067081\n",
      "MAP@100: 0.019830 | Precision@100: 0.015203 | Recall@100: 0.104349\n",
      "MAP@200: 0.016507 | Precision@200: 0.011716 | Recall@200: 0.153125\n",
      "MAP@300: 0.014583 | Precision@300: 0.009886 | Recall@300: 0.187361\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_full = torch.from_numpy(_filtered_valid_full[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_idx_valid_full = torch.from_numpy(_filtered_valid_full['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = recommendations[users_idx_valid_full, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_full, users_idx=users_idx_valid_full, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_full, k, users_idx_valid_full, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.034274 | Precision@5: 0.030199 | Recall@5: 0.012502\n",
      "MAP@10: 0.030265 | Precision@10: 0.025033 | Recall@10: 0.020436\n",
      "MAP@50: 0.022435 | Precision@50: 0.017907 | Recall@50: 0.065057\n",
      "MAP@100: 0.019333 | Precision@100: 0.015099 | Recall@100: 0.102046\n",
      "MAP@200: 0.016192 | Precision@200: 0.011510 | Recall@200: 0.152373\n",
      "MAP@300: 0.014326 | Precision@300: 0.009700 | Recall@300: 0.189482\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_valid = torch.from_numpy(_filtered_valid_valid[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_idx_valid_valid = torch.from_numpy(_filtered_valid_valid['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = recommendations[users_idx_valid_valid, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_valid, users_idx=users_idx_valid_valid, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_valid, k, users_idx_valid_valid, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies2 = movies.merge(movie_id_map, on=\"movieId\").drop([\"movieId\", \"title\"], axis=1)\n",
    "movies_genres_exploded = movies2[\"genres\"].str.split(\"|\").explode()\n",
    "genres_map = {genre:i for i, genre in enumerate(movies_genres_exploded.unique())}\n",
    "genres_one_hot = pd.get_dummies(movies_genres_exploded).astype(np.int8).groupby(level=0).sum()\n",
    "item_features = genres_one_hot.reset_index().rename(columns={'index': 'item_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47391</th>\n",
       "      <td>47391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47392</th>\n",
       "      <td>47392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47393</th>\n",
       "      <td>47393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47394</th>\n",
       "      <td>47394</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47395</th>\n",
       "      <td>47395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47396 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  (no genres listed)  Action  Adventure  Animation  Children  \\\n",
       "0            0                   0       0          1          1         1   \n",
       "1            1                   0       0          1          0         1   \n",
       "2            2                   0       0          0          0         0   \n",
       "3            3                   0       0          0          0         0   \n",
       "4            4                   0       0          0          0         0   \n",
       "...        ...                 ...     ...        ...        ...       ...   \n",
       "47391    47391                   0       0          0          0         0   \n",
       "47392    47392                   0       0          0          0         0   \n",
       "47393    47393                   1       0          0          0         0   \n",
       "47394    47394                   0       1          0          0         0   \n",
       "47395    47395                   0       0          0          0         0   \n",
       "\n",
       "       Comedy  Crime  Documentary  Drama  ...  Film-Noir  Horror  IMAX  \\\n",
       "0           1      0            0      0  ...          0       0     0   \n",
       "1           0      0            0      0  ...          0       0     0   \n",
       "2           1      0            0      0  ...          0       0     0   \n",
       "3           1      0            0      1  ...          0       0     0   \n",
       "4           1      0            0      0  ...          0       0     0   \n",
       "...       ...    ...          ...    ...  ...        ...     ...   ...   \n",
       "47391       0      0            1      0  ...          0       0     0   \n",
       "47392       0      1            0      0  ...          0       1     0   \n",
       "47393       0      0            0      0  ...          0       0     0   \n",
       "47394       1      0            0      0  ...          0       0     0   \n",
       "47395       1      0            0      1  ...          0       0     0   \n",
       "\n",
       "       Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0            0        0        0       0         0    0        0  \n",
       "1            0        0        0       0         0    0        0  \n",
       "2            0        0        1       0         0    0        0  \n",
       "3            0        0        1       0         0    0        0  \n",
       "4            0        0        0       0         0    0        0  \n",
       "...        ...      ...      ...     ...       ...  ...      ...  \n",
       "47391        0        0        0       0         0    0        0  \n",
       "47392        0        0        0       0         0    0        0  \n",
       "47393        0        0        0       0         0    0        0  \n",
       "47394        0        0        1       0         0    0        0  \n",
       "47395        0        0        0       0         0    0        0  \n",
       "\n",
       "[47396 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_85929/1218336675.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_categories_agg = ratings_train.groupby(\"session_id\").apply(get_categories_agg).reset_index()\n"
     ]
    }
   ],
   "source": [
    "user_features = pd.DataFrame({\"session_id\": range(n_users)})\n",
    "\n",
    "# rating\n",
    "def minmax_scale(x, min_, max_):\n",
    "    return (x - min_) / (max_ - min_)\n",
    "\n",
    "mean_ratings = minmax_scale(ratings_train.groupby(\"session_id\")[\"rating\"].mean(), 0, 5).reset_index(name=\"mean_rating\")\n",
    "average_mean_rating = mean_ratings[\"mean_rating\"].mean()\n",
    "user_features = user_features.merge(mean_ratings, on=\"session_id\", how=\"left\").fillna(average_mean_rating)\n",
    "\n",
    "# category\n",
    "def get_categories_agg(x):\n",
    "    agg = genres_one_hot.iloc[x[\"item_id\"]].sum(axis=0)\n",
    "    return agg / agg.values.sum()\n",
    "\n",
    "user_categories_agg = ratings_train.groupby(\"session_id\").apply(get_categories_agg).reset_index()\n",
    "average_user_categories_agg = user_categories_agg.drop(\"session_id\", axis=1).mean(axis=0)\n",
    "\n",
    "categories_cols = user_categories_agg.drop(\"session_id\", axis=1).columns\n",
    "\n",
    "user_features = user_features.merge(user_categories_agg, on=\"session_id\", how=\"left\").fillna(average_user_categories_agg)\n",
    "\n",
    "# n items\n",
    "user_n_items = ratings_train.groupby(\"session_id\").size().reset_index(name=\"n_items\")\n",
    "user_features = user_features.merge(user_n_items, on=\"session_id\", how=\"left\").fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>n_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.874667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.109756</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.059761</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>0.183267</td>\n",
       "      <td>0.051793</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.107570</td>\n",
       "      <td>0.035857</td>\n",
       "      <td>0.087649</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162409</th>\n",
       "      <td>162409</td>\n",
       "      <td>0.856976</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.061305</td>\n",
       "      <td>0.053226</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.170023</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.092870</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162410</th>\n",
       "      <td>162410</td>\n",
       "      <td>0.856976</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.061305</td>\n",
       "      <td>0.053226</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.170023</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.092870</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162411</th>\n",
       "      <td>162411</td>\n",
       "      <td>0.856976</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.061305</td>\n",
       "      <td>0.053226</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.170023</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.092870</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162412</th>\n",
       "      <td>162412</td>\n",
       "      <td>0.856976</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.061305</td>\n",
       "      <td>0.053226</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.170023</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.092870</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162413</th>\n",
       "      <td>162413</td>\n",
       "      <td>0.856976</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.061305</td>\n",
       "      <td>0.053226</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.170023</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.092870</td>\n",
       "      <td>0.039975</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162414 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  mean_rating  (no genres listed)    Action  Adventure  \\\n",
       "0                0     0.883333            0.000000  0.048387   0.080645   \n",
       "1                1     0.874667            0.000000  0.073171   0.048780   \n",
       "2                2     0.875862            0.000000  0.063745   0.059761   \n",
       "3                3     0.850000            0.000000  0.083333   0.035714   \n",
       "4                4     0.900000            0.000000  0.071429   0.035714   \n",
       "...            ...          ...                 ...       ...        ...   \n",
       "162409      162409     0.856976            0.000841  0.061305   0.053226   \n",
       "162410      162410     0.856976            0.000841  0.061305   0.053226   \n",
       "162411      162411     0.856976            0.000841  0.061305   0.053226   \n",
       "162412      162412     0.856976            0.000841  0.061305   0.053226   \n",
       "162413      162413     0.856976            0.000841  0.061305   0.053226   \n",
       "\n",
       "        Animation  Children    Comedy     Crime  Documentary  ...    Horror  \\\n",
       "0        0.080645  0.096774  0.129032  0.048387     0.032258  ...  0.000000   \n",
       "1        0.012195  0.048780  0.195122  0.042683     0.012195  ...  0.024390   \n",
       "2        0.019920  0.055777  0.183267  0.051793     0.015936  ...  0.015936   \n",
       "3        0.000000  0.023810  0.178571  0.047619     0.011905  ...  0.011905   \n",
       "4        0.011905  0.023810  0.190476  0.059524     0.035714  ...  0.023810   \n",
       "...           ...       ...       ...       ...          ...  ...       ...   \n",
       "162409   0.014152  0.030705  0.170023  0.041362     0.020966  ...  0.038396   \n",
       "162410   0.014152  0.030705  0.170023  0.041362     0.020966  ...  0.038396   \n",
       "162411   0.014152  0.030705  0.170023  0.041362     0.020966  ...  0.038396   \n",
       "162412   0.014152  0.030705  0.170023  0.041362     0.020966  ...  0.038396   \n",
       "162413   0.014152  0.030705  0.170023  0.041362     0.020966  ...  0.038396   \n",
       "\n",
       "            IMAX   Musical   Mystery   Romance    Sci-Fi  Thriller       War  \\\n",
       "0       0.000000  0.080645  0.000000  0.064516  0.048387  0.096774  0.016129   \n",
       "1       0.006098  0.012195  0.024390  0.109756  0.036585  0.121951  0.006098   \n",
       "2       0.003984  0.007968  0.019920  0.107570  0.035857  0.087649  0.019920   \n",
       "3       0.000000  0.011905  0.035714  0.130952  0.035714  0.107143  0.011905   \n",
       "4       0.000000  0.011905  0.011905  0.107143  0.023810  0.119048  0.000000   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "162409  0.001535  0.020651  0.025649  0.092870  0.039975  0.077798  0.019673   \n",
       "162410  0.001535  0.020651  0.025649  0.092870  0.039975  0.077798  0.019673   \n",
       "162411  0.001535  0.020651  0.025649  0.092870  0.039975  0.077798  0.019673   \n",
       "162412  0.001535  0.020651  0.025649  0.092870  0.039975  0.077798  0.019673   \n",
       "162413  0.001535  0.020651  0.025649  0.092870  0.039975  0.077798  0.019673   \n",
       "\n",
       "         Western  n_items  \n",
       "0       0.000000     24.0  \n",
       "1       0.000000     75.0  \n",
       "2       0.000000    116.0  \n",
       "3       0.000000     40.0  \n",
       "4       0.000000     40.0  \n",
       "...          ...      ...  \n",
       "162409  0.006239      0.0  \n",
       "162410  0.006239      0.0  \n",
       "162411  0.006239      0.0  \n",
       "162412  0.006239      0.0  \n",
       "162413  0.006239      0.0  \n",
       "\n",
       "[162414 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel, rel_sum, rel_mask = recommendation_relevance(recommendations[users_idx_valid_full], ground_truth_valid_full, users_idx=users_idx_valid_full, n_users=n_users, n_items=n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indices = users_idx_valid_full\n",
    "true_indices_2d = true_indices.repeat(N_candid, 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = torch.stack([true_indices_2d, recommendations[users_idx_valid_full][rel_mask], rel[rel_mask]], dim=-1)\n",
    "triples_list = [tuple(triple) for triple in triples.reshape(-1, 3).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(triples_list, columns=[\"session_id\", \"item_id\", \"label\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.merge(user_features).merge(item_features, on=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross features\n",
    "a = df_features[[f\"{i}_x\" for i in categories_cols]].values\n",
    "b = df_features[[f\"{i}_y\" for i in categories_cols]].values\n",
    "df_features[\"item_categories_dot\"] = (a * b).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_features[df_features[\"session_id\"].isin(train_users)]\n",
    "test_df = df_features[df_features[\"session_id\"].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train_df.columns if col not in ['label', \"session_id\", \"item_id\"]]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5259, number of negative: 522441\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5905\n",
      "[LightGBM] [Info] Number of data points in the train set: 527700, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.009966 -> initscore=-4.598571\n",
      "[LightGBM] [Info] Start training from score -4.598571\n",
      "Train:  Log Loss: 0.039185 | Accuracy: 0.990119 | Precision: 0.643312 | Recall: 0.019205\n",
      "Test:  Log Loss: 0.055474 | Accuracy: 0.989430 | Precision: 0.037559 | Recall: 0.003641\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score\n",
    "\n",
    "model = lgb.LGBMClassifier(objective='binary', random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "for X, y, type in zip([X_train, X_test], [y_train, y_test], [\"Train\", \"Test\"]):\n",
    "    y_pred_scores = model.predict_proba(X)[:, 1] # type: ignore\n",
    "    loss = log_loss(y, y_pred_scores)\n",
    "    y_pred = (y_pred_scores >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    print(f\"{type}:  Log Loss: {loss:.6f} | Accuracy: {accuracy:.6f} | Precision: {precision:.6f} | Recall: {recall:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_85929/2544054520.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n",
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_85929/2544054520.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n"
     ]
    }
   ],
   "source": [
    "def reranker(model, X_test, df):\n",
    "    \"\"\"\n",
    "    Predict scores for each candidate using the trained model.\n",
    "    Groups items by session_id and sorts item_ids in descending order.\n",
    "    Returns a dataframe with session_id and the ranked candidates as a list.\n",
    "    \"\"\"\n",
    "    scores = model.predict_proba(X_test)[:, 1]\n",
    "    df = df.copy()\n",
    "    df['score'] = scores\n",
    "    reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n",
    "    return reranked\n",
    "\n",
    "reranked_recommendations_valid_train = torch.tensor(reranker(model, X_train, train_df)[\"candidates\"].values.tolist())\n",
    "reranked_recommendations_valid_valid = torch.tensor(reranker(model, X_test, test_df)[\"candidates\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.119776 | Precision@5: 0.089028 | Recall@5: 0.037574\n",
      "MAP@10: 0.095619 | Precision@10: 0.062365 | Recall@10: 0.053141\n",
      "MAP@50: 0.048070 | Precision@50: 0.025696 | Recall@50: 0.095909\n",
      "MAP@100: 0.034611 | Precision@100: 0.018198 | Recall@100: 0.128117\n",
      "MAP@200: 0.024941 | Precision@200: 0.013081 | Recall@200: 0.170264\n",
      "MAP@300: 0.020455 | Precision@300: 0.009966 | Recall@300: 0.186450\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_train = torch.from_numpy(_filtered_valid_train[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_id_valid_train = torch.from_numpy(_filtered_valid_train['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = reranked_recommendations_valid_train[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_train, users_idx=users_id_valid_train, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_train, k, users_id_valid_train, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.019179 | Precision@5: 0.019073 | Recall@5: 0.008503\n",
      "MAP@10: 0.017814 | Precision@10: 0.016026 | Recall@10: 0.013076\n",
      "MAP@50: 0.014976 | Precision@50: 0.012848 | Recall@50: 0.047995\n",
      "MAP@100: 0.013658 | Precision@100: 0.011748 | Recall@100: 0.080741\n",
      "MAP@200: 0.012482 | Precision@200: 0.010715 | Recall@200: 0.144105\n",
      "MAP@300: 0.011740 | Precision@300: 0.009700 | Recall@300: 0.189482\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_valid = torch.from_numpy(_filtered_valid_valid[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_idx_valid_valid = torch.from_numpy(_filtered_valid_valid['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = reranked_recommendations_valid_valid[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_valid, users_idx=users_idx_valid_valid, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_valid, k, users_idx_valid_valid, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids_train = train_df.groupby(\"session_id\")[\"session_id\"].count().to_numpy()\n",
    "qids_test = test_df.groupby(\"session_id\")[\"session_id\"].count().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    verbosity=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.915732\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.424930\n",
      "[LightGBM] [Debug] init for col-wise cost 0.010782 seconds, init for row-wise cost 0.027726 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 5905\n",
      "[LightGBM] [Info] Number of data points in the train set: 527700, number of used features: 43\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;, verbosity=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMRanker</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRanker(metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;, verbosity=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker(metric='ndcg', objective='lambdarank', verbosity=10)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    group=qids_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[qids_test],\n",
    "    eval_at=[10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.20259238, -1.2723647 , -0.57917481, ..., -0.36825933,\n",
       "       -0.17223499, -0.79918447], shape=(226500,))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_85929/1533776108.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n",
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_85929/1533776108.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n"
     ]
    }
   ],
   "source": [
    "def reranker(model, X_test, df):\n",
    "    \"\"\"\n",
    "    Predict scores for each candidate using the trained model.\n",
    "    Groups items by session_id and sorts item_ids in descending order.\n",
    "    Returns a dataframe with session_id and the ranked candidates as a list.\n",
    "    \"\"\"\n",
    "    scores = model.predict(X_test)\n",
    "    df = df.copy()\n",
    "    df['score'] = scores\n",
    "    reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n",
    "    return reranked\n",
    "\n",
    "reranked_recommendations_valid_train = torch.tensor(reranker(model, X_train, train_df)[\"candidates\"].values.tolist())\n",
    "reranked_recommendations_valid_valid = torch.tensor(reranker(model, X_test, test_df)[\"candidates\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.148340 | Precision@5: 0.095736 | Recall@5: 0.061910\n",
      "MAP@10: 0.109879 | Precision@10: 0.060887 | Recall@10: 0.074908\n",
      "MAP@50: 0.047743 | Precision@50: 0.021558 | Recall@50: 0.111145\n",
      "MAP@100: 0.032723 | Precision@100: 0.015281 | Recall@100: 0.135644\n",
      "MAP@200: 0.023033 | Precision@200: 0.012001 | Recall@200: 0.171179\n",
      "MAP@300: 0.018999 | Precision@300: 0.009966 | Recall@300: 0.186450\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_train = torch.from_numpy(_filtered_valid_train[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_id_valid_train = torch.from_numpy(_filtered_valid_train['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = reranked_recommendations_valid_train[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_train, users_idx=users_id_valid_train, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_train, k, users_id_valid_train, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.022415 | Precision@5: 0.020132 | Recall@5: 0.006202\n",
      "MAP@10: 0.020070 | Precision@10: 0.016159 | Recall@10: 0.012012\n",
      "MAP@50: 0.014674 | Precision@50: 0.011974 | Recall@50: 0.043115\n",
      "MAP@100: 0.013072 | Precision@100: 0.010901 | Recall@100: 0.075810\n",
      "MAP@200: 0.011817 | Precision@200: 0.010192 | Recall@200: 0.134365\n",
      "MAP@300: 0.011202 | Precision@300: 0.009700 | Recall@300: 0.189482\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_valid = torch.from_numpy(_filtered_valid_valid[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_idx_valid_valid = torch.from_numpy(_filtered_valid_valid['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = reranked_recommendations_valid_valid[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_valid, users_idx=users_idx_valid_valid, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_valid, k, users_idx_valid_valid, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class DeepFMDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "        self.X = self.df.values\n",
    "        self.y = self.df[\"label\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = torch.tensor(self.X[index], dtype=torch.float32)\n",
    "        label = torch.tensor(self.y[index], dtype=torch.float32).unsqueeze(0)\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapping = SimpleNamespace(\n",
    "    dense={\n",
    "        \"mean_rating\": {\n",
    "            \"index\": train_df.columns.get_loc(\"mean_rating\")\n",
    "        }, \n",
    "        \"item_categories_dot\": {\n",
    "            \"index\": train_df.columns.get_loc(\"item_categories_dot\")\n",
    "        }\n",
    "    },\n",
    "    sparse={},\n",
    "    varlen={\n",
    "        \"user_item_categories\": {\n",
    "            \"index\": [train_df.columns.get_loc(f\"{i}_x\") for i in categories_cols],\n",
    "            \"num_emb\": len(categories_cols)\n",
    "        },\n",
    "        \"item_categories\": {\n",
    "            \"index\": [train_df.columns.get_loc(f\"{i}_y\") for i in categories_cols],\n",
    "            \"num_emb\": len(categories_cols)\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFMTrainer:\n",
    "    def __init__(self, model_config, train_config, dataset, device: \"torch.device\"):\n",
    "        self.model_config = model_config\n",
    "        self.train_config = train_config\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.datasets = self._init_datasets()\n",
    "        self.loaders = self._init_loaders()\n",
    "        self.model = self._init_model()\n",
    "        self.optimizer = self._init_optimizer()\n",
    "        self.criterion = self._init_criterion()\n",
    "\n",
    "    def _init_model(self) -> nn.Module:\n",
    "        model = DeepFM(feature_mapping, 8, [20, 25, 16]).to(\n",
    "            self.device\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def _init_optimizer(self) -> torch.optim.Optimizer:\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.train_config.lr)\n",
    "\n",
    "    def _init_criterion(self) -> nn.Module:\n",
    "        return nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def _init_datasets(self) -> dict[str, Dataset]:\n",
    "        train_dataset = DeepFMDataset(train_df)\n",
    "        val_dataset = DeepFMDataset(test_df)\n",
    "\n",
    "        return {\"train\": train_dataset, \"val\": val_dataset, \"eval\": None}\n",
    "\n",
    "    def _init_loaders(self) -> dict[str, DataLoader]:\n",
    "        train_loader = DataLoader(self.datasets[\"train\"], batch_size=self.train_config.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(self.datasets[\"val\"], batch_size=self.train_config.batch_size, shuffle=False)\n",
    "\n",
    "        return {\"train\": train_loader, \"val\": val_loader, \"eval\": None}\n",
    "\n",
    "    def train(self, print_every: None | int = None) -> tuple[float, float]:\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        preds, ground_truths = [], []\n",
    "\n",
    "        for batch_idx, batch in enumerate(self.loaders[\"train\"]):\n",
    "            data, target = batch[0].to(self.device), batch[1].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            loss_item = loss.detach().cpu().item()\n",
    "\n",
    "            if print_every is not None and batch_idx % print_every == 0:\n",
    "                percentage = 100.0 * batch_idx / len(self.loaders[\"train\"])\n",
    "                print(f\"Train (Batch): [{batch_idx}/{len(self.loaders['train'])} ({percentage:.0f}%)] | Loss: {loss_item:.4f}\")\n",
    "\n",
    "            preds.append(output)\n",
    "            ground_truths.append(target)\n",
    "            train_loss += loss_item\n",
    "\n",
    "        train_loss /= len(self.loaders[\"train\"])\n",
    "\n",
    "        pred = torch.cat(preds, dim=0).detach().sigmoid().cpu().numpy()\n",
    "        ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
    "        train_roc_auc = float(roc_auc_score(ground_truth, pred))\n",
    "\n",
    "        print(f\"\\nTrain: Loss: {train_loss:.4f} | ROC AUC: {train_roc_auc:.4f}\")\n",
    "\n",
    "        return train_loss, train_roc_auc\n",
    "\n",
    "    def test(self) -> tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        test_loss = 0.0\n",
    "        preds, ground_truths = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(self.loaders[\"val\"]):\n",
    "                data, target = batch[0].to(self.device), batch[1].to(self.device)\n",
    "\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "\n",
    "                preds.append(output)\n",
    "                ground_truths.append(target)\n",
    "                test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        pred = torch.cat(preds, dim=0).sigmoid().cpu().numpy()\n",
    "        ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "        test_roc_auc = float(roc_auc_score(ground_truth, pred))\n",
    "        test_loss /= len(self.loaders[\"val\"])\n",
    "\n",
    "        print(f\"Test: Loss: {test_loss:.4f} | ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "        return test_loss, test_roc_auc\n",
    "\n",
    "    def fit(self):\n",
    "        history = {\"train_loss\": [], \"train_roc_auc\": [], \"test_loss\": [], \"test_roc_auc\": []}\n",
    "        for epoch in tqdm(range(1, self.train_config.epochs + 1)):\n",
    "            train_loss, train_roc_auc = self.train(print_every=self.train_config.train_print_every)\n",
    "            test_loss, test_roc_auc = self.test()\n",
    "\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_roc_auc\"].append(train_roc_auc)\n",
    "            history[\"test_loss\"].append(test_loss)\n",
    "            history[\"test_roc_auc\"].append(test_roc_auc)\n",
    "\n",
    "        return history\n",
    "\n",
    "trainer = DeepFMTrainer(\n",
    "    None, \n",
    "    TrainConfig(valid_size=0.2, batch_size=256, train_print_every=1000, neg_sampl=1, lr=1e-3, epochs=7, eval_user_batch_size=1000, eval_batch_size=1), \n",
    "    dataset=ds, \n",
    "    device=torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Batch): [0/2062 (0%)] | Loss: 0.7536\n",
      "Train (Batch): [1000/2062 (48%)] | Loss: 0.0809\n",
      "Train (Batch): [2000/2062 (97%)] | Loss: 0.0444\n",
      "\n",
      "Train: Loss: 0.1026 | ROC AUC: 0.5191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:07<00:44,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.0543 | ROC AUC: 0.5775\n",
      "Train (Batch): [0/2062 (0%)] | Loss: 0.0323\n",
      "Train (Batch): [1000/2062 (48%)] | Loss: 0.0125\n",
      "Train (Batch): [2000/2062 (97%)] | Loss: 0.0312\n",
      "\n",
      "Train: Loss: 0.0574 | ROC AUC: 0.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:14<00:37,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.0542 | ROC AUC: 0.5879\n",
      "Train (Batch): [0/2062 (0%)] | Loss: 0.0230\n",
      "Train (Batch): [1000/2062 (48%)] | Loss: 0.0249\n",
      "Train (Batch): [2000/2062 (97%)] | Loss: 0.0457\n",
      "\n",
      "Train: Loss: 0.0563 | ROC AUC: 0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:22<00:29,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.0539 | ROC AUC: 0.6177\n",
      "Train (Batch): [0/2062 (0%)] | Loss: 0.0126\n",
      "Train (Batch): [1000/2062 (48%)] | Loss: 0.0630\n",
      "Train (Batch): [2000/2062 (97%)] | Loss: 0.0800\n",
      "\n",
      "Train: Loss: 0.0557 | ROC AUC: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:29<00:22,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.0535 | ROC AUC: 0.6360\n",
      "Train (Batch): [0/2062 (0%)] | Loss: 0.0382\n",
      "Train (Batch): [1000/2062 (48%)] | Loss: 0.0494\n",
      "Train (Batch): [2000/2062 (97%)] | Loss: 0.1502\n",
      "\n",
      "Train: Loss: 0.0553 | ROC AUC: 0.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:36<00:14,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.0530 | ROC AUC: 0.6596\n",
      "Train (Batch): [0/2062 (0%)] | Loss: 0.0801\n",
      "Train (Batch): [1000/2062 (48%)] | Loss: 0.0445\n",
      "Train (Batch): [2000/2062 (97%)] | Loss: 0.0431\n",
      "\n",
      "Train: Loss: 0.0548 | ROC AUC: 0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [00:44<00:07,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.0529 | ROC AUC: 0.6608\n",
      "Train (Batch): [0/2062 (0%)] | Loss: 0.0209\n",
      "Train (Batch): [1000/2062 (48%)] | Loss: 0.0649\n",
      "Train (Batch): [2000/2062 (97%)] | Loss: 0.0733\n",
      "\n",
      "Train: Loss: 0.0545 | ROC AUC: 0.6421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:51<00:00,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.0530 | ROC AUC: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.10262096733049961,\n",
       "  0.05738352724756579,\n",
       "  0.05630157323496346,\n",
       "  0.05572316422200356,\n",
       "  0.05527511553452228,\n",
       "  0.05477201480600914,\n",
       "  0.05450940691747646],\n",
       " 'train_roc_auc': [0.5191164612679358,\n",
       "  0.5598150225823935,\n",
       "  0.5868050834588783,\n",
       "  0.5999713248748888,\n",
       "  0.6107085451172198,\n",
       "  0.6304504035575983,\n",
       "  0.6421289250890041],\n",
       " 'test_loss': [0.054269511145302804,\n",
       "  0.05418079556728908,\n",
       "  0.053865876168244134,\n",
       "  0.05348080054378021,\n",
       "  0.052978715397375455,\n",
       "  0.05291164955071642,\n",
       "  0.05297117433116093],\n",
       " 'test_roc_auc': [0.5775068080163388,\n",
       "  0.587876329975174,\n",
       "  0.6177364707779913,\n",
       "  0.6360447033401652,\n",
       "  0.6595910579545142,\n",
       "  0.6607535150039086,\n",
       "  0.6695420416816983]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    scores = []\n",
    "    for batch in trainer.datasets[\"val\"]:\n",
    "        scores.append(trainer.model(batch[0].unsqueeze(0)).squeeze(0))\n",
    "    scores = torch.vstack(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_85929/449248687.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n",
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_85929/449248687.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n"
     ]
    }
   ],
   "source": [
    "def score(ds):\n",
    "    with torch.no_grad():\n",
    "        scores = []\n",
    "        for batch in trainer.datasets[ds]:\n",
    "            scores.append(trainer.model(batch[0].unsqueeze(0)).squeeze(0))\n",
    "        scores = torch.vstack(scores)\n",
    "    return scores\n",
    "\n",
    "def reranker(scores, df):\n",
    "    df = df.copy()\n",
    "    df['score'] = scores.numpy()\n",
    "    reranked = df.groupby('session_id').apply(lambda x: x.sort_values(by='score', ascending=False)['item_id'].tolist()).reset_index(name='candidates')\n",
    "    return reranked\n",
    "\n",
    "reranked_recommendations_valid_train = torch.tensor(reranker(score(\"train\"), train_df)[\"candidates\"].values.tolist())\n",
    "reranked_recommendations_valid_valid = torch.tensor(reranker(score(\"val\"), test_df)[\"candidates\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.023498 | Precision@5: 0.021603 | Recall@5: 0.008353\n",
      "MAP@10: 0.022406 | Precision@10: 0.020637 | Recall@10: 0.015742\n",
      "MAP@50: 0.017477 | Precision@50: 0.014360 | Recall@50: 0.047936\n",
      "MAP@100: 0.015470 | Precision@100: 0.012922 | Recall@100: 0.086507\n",
      "MAP@200: 0.013702 | Precision@200: 0.011072 | Recall@200: 0.140593\n",
      "MAP@300: 0.012657 | Precision@300: 0.009966 | Recall@300: 0.186450\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_train = torch.from_numpy(_filtered_valid_train[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_id_valid_train = torch.from_numpy(_filtered_valid_train['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = reranked_recommendations_valid_train[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_train, users_idx=users_id_valid_train, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_train, k, users_id_valid_train, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.025965 | Precision@5: 0.023311 | Recall@5: 0.009383\n",
      "MAP@10: 0.023343 | Precision@10: 0.019470 | Recall@10: 0.013727\n",
      "MAP@50: 0.017547 | Precision@50: 0.014172 | Recall@50: 0.051601\n",
      "MAP@100: 0.015341 | Precision@100: 0.012397 | Recall@100: 0.083993\n",
      "MAP@200: 0.013414 | Precision@200: 0.010722 | Recall@200: 0.142691\n",
      "MAP@300: 0.012361 | Precision@300: 0.009700 | Recall@300: 0.189482\n"
     ]
    }
   ],
   "source": [
    "ground_truth_valid_valid = torch.from_numpy(_filtered_valid_valid[['session_id', 'item_id']].values).T.to(torch.int32)\n",
    "users_idx_valid_valid = torch.from_numpy(_filtered_valid_valid['session_id'].unique()).to(torch.int32)\n",
    "\n",
    "for k in [5, 10, 50, 100, 200, 300]:\n",
    "    recommendations_k = reranked_recommendations_valid_valid[:, :k]\n",
    "    rel_output = recommendation_relevance(recommendations_k, ground_truth_valid_valid, users_idx=users_idx_valid_valid, n_users=n_users, n_items=n_items)\n",
    "\n",
    "    map = map_k(recommendations_k, ground_truth_valid_valid, k, users_idx_valid_valid, n_users, n_items)\n",
    "    prec = precision_k_rel(*rel_output)\n",
    "    rec = recall_k_rel(*rel_output)\n",
    "\n",
    "    print(f\"MAP@{k}: {map:.6f} | Precision@{k}: {prec:.6f} | Recall@{k}: {rec:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
